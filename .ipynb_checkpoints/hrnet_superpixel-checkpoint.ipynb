{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 加载依赖库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, Permute, Dense, Activation, Flatten, Conv2D\n",
    "from keras.layers import MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, GlobalMaxPool2D, BatchNormalization\n",
    "from keras.layers import Convolution2D, UpSampling2D, AtrousConvolution2D, ZeroPadding2D, Lambda, Conv2DTranspose\n",
    "from keras.layers import multiply, add, concatenate, Concatenate\n",
    "from keras.layers import LocallyConnected2D\n",
    "from keras.layers import add\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import cv2\n",
    "import random\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "import tifffile\n",
    "from keras.backend import tf as ktf\n",
    "from glob import glob\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 全局变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CLASS = 5\n",
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 512\n",
    "\n",
    "# 数据路径\n",
    "img_type = '.tif'\n",
    "TRAIN_TOP_PATH = 'E:/Semantic-Segmentation/four_dataset/VAIHINGEN/train_crop_top/'\n",
    "\n",
    "VAL_TOP_PATH = 'E:/Semantic-Segmentation/four_dataset/VAIHINGEN/test_crop_top/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import UpSampling2D, add, concatenate, Dropout\n",
    "from HRNet_superpixel.keras_superpixel_pooling import *\n",
    "from HRNet_superpixel.keras_superpixel_unpooling import *\n",
    "\n",
    "\n",
    "def conv3x3(x, out_filters, strides=(1, 1)):\n",
    "    x = Conv2D(out_filters, 3, padding='same', strides=strides, use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def basic_Block(input, out_filters, strides=(1, 1), with_conv_shortcut=False):\n",
    "    x = conv3x3(input, out_filters, strides)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = conv3x3(x, out_filters)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "\n",
    "    if with_conv_shortcut:\n",
    "        residual = Conv2D(out_filters, 1, strides=strides, use_bias=False, kernel_initializer='he_normal')(input)\n",
    "        residual = BatchNormalization(axis=3)(residual)\n",
    "        x = add([x, residual])\n",
    "    else:\n",
    "        x = add([x, input])\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def bottleneck_Block(input, out_filters, strides=(1, 1), with_conv_shortcut=False):\n",
    "    expansion = 4\n",
    "    de_filters = int(out_filters / expansion)\n",
    "\n",
    "    x = Conv2D(de_filters, 1, use_bias=False, kernel_initializer='he_normal')(input)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(de_filters, 3, strides=strides, padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(out_filters, 1, use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "\n",
    "    if with_conv_shortcut:\n",
    "        residual = Conv2D(out_filters, 1, strides=strides, use_bias=False, kernel_initializer='he_normal')(input)\n",
    "        residual = BatchNormalization(axis=3)(residual)\n",
    "        x = add([x, residual])\n",
    "    else:\n",
    "        x = add([x, input])\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def stem_net(input):\n",
    "    x = Conv2D(64, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(input)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # x = Conv2D(64, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    # x = BatchNormalization(axis=3)(x)\n",
    "    # x = Activation('relu')(x)\n",
    "\n",
    "    x = bottleneck_Block(x, 256, with_conv_shortcut=True)\n",
    "    x = bottleneck_Block(x, 256, with_conv_shortcut=False)\n",
    "    x = bottleneck_Block(x, 256, with_conv_shortcut=False)\n",
    "    x = bottleneck_Block(x, 256, with_conv_shortcut=False)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_layer1(x, out_filters_list=[32, 64]):\n",
    "    x0 = Conv2D(out_filters_list[0], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    x0 = BatchNormalization(axis=3)(x0)\n",
    "    x0 = Activation('relu')(x0)\n",
    "\n",
    "    x1 = Conv2D(out_filters_list[1], 3, strides=(2, 2),\n",
    "                padding='same', use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    x1 = BatchNormalization(axis=3)(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "    return [x0, x1]\n",
    "\n",
    "\n",
    "def make_branch1_0(x, out_filters=32):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_branch1_1(x, out_filters=64):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def fuse_layer1(x):\n",
    "    x0_0 = x[0]\n",
    "    x0_1 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[1])\n",
    "    x0_1 = BatchNormalization(axis=3)(x0_1)\n",
    "    x0_1 = UpSampling2D(size=(2, 2))(x0_1)\n",
    "    x0 = add([x0_0, x0_1])\n",
    "\n",
    "    x1_0 = Conv2D(64, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x[0])\n",
    "    x1_0 = BatchNormalization(axis=3)(x1_0)\n",
    "    x1_1 = x[1]\n",
    "    x1 = add([x1_0, x1_1])\n",
    "    return [x0, x1]\n",
    "\n",
    "\n",
    "def transition_layer2(x, out_filters_list=[32, 64, 128]):\n",
    "    x0 = Conv2D(out_filters_list[0], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x[0])\n",
    "    x0 = BatchNormalization(axis=3)(x0)\n",
    "    x0 = Activation('relu')(x0)\n",
    "\n",
    "    x1 = Conv2D(out_filters_list[1], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x[1])\n",
    "    x1 = BatchNormalization(axis=3)(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "    x2 = Conv2D(out_filters_list[2], 3, strides=(2, 2),\n",
    "                padding='same', use_bias=False, kernel_initializer='he_normal')(x[1])\n",
    "    x2 = BatchNormalization(axis=3)(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "\n",
    "    return [x0, x1, x2]\n",
    "\n",
    "\n",
    "def make_branch2_0(x, out_filters=32):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_branch2_1(x, out_filters=64):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_branch2_2(x, out_filters=128):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def fuse_layer2(x):\n",
    "    x0_0 = x[0]\n",
    "    x0_1 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[1])\n",
    "    x0_1 = BatchNormalization(axis=3)(x0_1)\n",
    "    x0_1 = UpSampling2D(size=(2, 2))(x0_1)\n",
    "    x0_2 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[2])\n",
    "    x0_2 = BatchNormalization(axis=3)(x0_2)\n",
    "    x0_2 = UpSampling2D(size=(4, 4))(x0_2)\n",
    "    x0 = add([x0_0, x0_1, x0_2])\n",
    "\n",
    "    x1_0 = Conv2D(64, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x[0])\n",
    "    x1_0 = BatchNormalization(axis=3)(x1_0)\n",
    "    x1_1 = x[1]\n",
    "    x1_2 = Conv2D(64, 1, use_bias=False, kernel_initializer='he_normal')(x[2])\n",
    "    x1_2 = BatchNormalization(axis=3)(x1_2)\n",
    "    x1_2 = UpSampling2D(size=(2, 2))(x1_2)\n",
    "    x1 = add([x1_0, x1_1, x1_2])\n",
    "\n",
    "    x2_0 = Conv2D(32, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x[0])\n",
    "    x2_0 = BatchNormalization(axis=3)(x2_0)\n",
    "    x2_0 = Activation('relu')(x2_0)\n",
    "    x2_0 = Conv2D(128, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x2_0)\n",
    "    x2_0 = BatchNormalization(axis=3)(x2_0)\n",
    "    x2_1 = Conv2D(128, 3, strides=(2, 2), padding='same', use_bias=False, kernel_initializer='he_normal')(x[1])\n",
    "    x2_1 = BatchNormalization(axis=3)(x2_1)\n",
    "    x2_2 = x[2]\n",
    "    x2 = add([x2_0, x2_1, x2_2])\n",
    "    return [x0, x1, x2]\n",
    "\n",
    "\n",
    "def transition_layer3(x, out_filters_list=[32, 64, 128, 256]):\n",
    "    x0 = Conv2D(out_filters_list[0], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x[0])\n",
    "    x0 = BatchNormalization(axis=3)(x0)\n",
    "    x0 = Activation('relu')(x0)\n",
    "\n",
    "    x1 = Conv2D(out_filters_list[1], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x[1])\n",
    "    x1 = BatchNormalization(axis=3)(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "    x2 = Conv2D(out_filters_list[2], 3, padding='same', use_bias=False, kernel_initializer='he_normal')(x[2])\n",
    "    x2 = BatchNormalization(axis=3)(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "\n",
    "    x3 = Conv2D(out_filters_list[3], 3, strides=(2, 2),\n",
    "                padding='same', use_bias=False, kernel_initializer='he_normal')(x[2])\n",
    "    x3 = BatchNormalization(axis=3)(x3)\n",
    "    x3 = Activation('relu')(x3)\n",
    "\n",
    "    return [x0, x1, x2, x3]\n",
    "\n",
    "\n",
    "def make_branch3_0(x, out_filters=32):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_branch3_1(x, out_filters=64):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_branch3_2(x, out_filters=128):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def make_branch3_3(x, out_filters=256):\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    x = basic_Block(x, out_filters, with_conv_shortcut=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "def fuse_layer3(x):\n",
    "    x0_0 = x[0]\n",
    "    x0_1 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[1])\n",
    "    x0_1 = BatchNormalization(axis=3)(x0_1)\n",
    "    x0_1 = UpSampling2D(size=(2, 2))(x0_1)\n",
    "    x0_2 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[2])\n",
    "    x0_2 = BatchNormalization(axis=3)(x0_2)\n",
    "    x0_2 = UpSampling2D(size=(4, 4))(x0_2)\n",
    "    x0_3 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x[3])\n",
    "    x0_3 = BatchNormalization(axis=3)(x0_3)\n",
    "    x0_3 = UpSampling2D(size=(8, 8))(x0_3)\n",
    "    x0 = concatenate([x0_0, x0_1, x0_2, x0_3], axis=-1)\n",
    "    return x0\n",
    "\n",
    "\n",
    "def final_layer(x, classes=1):\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(classes, 1, use_bias=False, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation('softmax', name='Classification')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def seg_hrnet(height=256, width=256, channel=3, classes=6):\n",
    "    inputs = Input(shape=(height, width, channel))\n",
    "    slic_feature_map = Input(shape=(height, width))\n",
    "\n",
    "    x0 = stem_net(inputs)\n",
    "\n",
    "    x1 = transition_layer1(x0)\n",
    "    x1_0 = make_branch1_0(x1[0])\n",
    "    x1_1 = make_branch1_1(x1[1])\n",
    "    x1 = fuse_layer1([x1_0, x1_1])\n",
    "\n",
    "    x2 = transition_layer2(x1)\n",
    "    x2_0 = make_branch2_0(x2[0])\n",
    "    x2_1 = make_branch2_1(x2[1])\n",
    "    x2_2 = make_branch2_2(x2[2])\n",
    "    x2 = fuse_layer2([x2_0, x2_1, x2_2])\n",
    "\n",
    "    x3 = transition_layer3(x2)\n",
    "    x3_0 = make_branch3_0(x3[0])\n",
    "    x3_1 = make_branch3_1(x3[1])\n",
    "    x3_2 = make_branch3_2(x3[2])\n",
    "    x3_3 = make_branch3_3(x3[3])\n",
    "    x3 = fuse_layer3([x3_0, x3_1, x3_2, x3_3])\n",
    "    x3 = UpSampling2D(size=(2, 2))(x3)\n",
    "\n",
    "    # ORIGINAL\n",
    "    x4_1 = Conv2D(32, 1, use_bias=False, kernel_initializer='he_normal')(x3)\n",
    "    x4_1 = BatchNormalization(axis=-1)(x4_1)\n",
    "\n",
    "    # SUPERPIXEL\n",
    "    x4_2 = SuperpixelPooling(num_superpixels=100, num_channels=128, batch_size=1,\n",
    "                             input_shapes=((height, width, 128), (height, width)))([x3, slic_feature_map])\n",
    "    x4_2 = Conv1D(32, 1, use_bias=False, kernel_initializer='he_normal')(x4_2)\n",
    "    x4_2 = BatchNormalization(axis=-1)(x4_2)\n",
    "    x4_2 = SuperpixelUnpooling(num_superpixels=100, num_channels=32, batch_size=1,\n",
    "                               superpixel_map_shapes=(height, width))([x4_2, slic_feature_map])\n",
    "\n",
    "    x4 = add([x4_1, x4_2])\n",
    "\n",
    "    out = final_layer(x4, classes=classes)\n",
    "\n",
    "    model = Model(inputs=[inputs, slic_feature_map], outputs=out)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 数据加载generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 读取一个batch的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取图片函数\n",
    "def read_img(top_paths):\n",
    "    top_imgs = []\n",
    "    label_imgs = []\n",
    "    for top_path in top_paths:\n",
    "        label_path = top_path.replace('top', 'label')\n",
    "        \n",
    "        top_img = tifffile.imread(top_path)\n",
    "        label_img = tifffile.imread(label_path)\n",
    "        \n",
    "        \n",
    "        top_img = top_img / 255.0\n",
    "        \n",
    "        label_img = np.expand_dims(label_img, axis=2)\n",
    "        label_img = np_utils.to_categorical(label_img, num_classes=6)\n",
    "        label_img = label_img[:, :, 0:5]\n",
    "\n",
    "        top_imgs.append(top_img)\n",
    "        label_imgs.append(label_img)\n",
    "\n",
    "    return np.array(top_imgs), np.array(label_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 获取批次函数，其实就是一个generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(top_path, batch_size):\n",
    "    while 1:\n",
    "        for i in range(0, len(top_path), batch_size):\n",
    "            top, label = read_img(top_path[i:i + batch_size])\n",
    "\n",
    "            yield ({'input_1': top}, {'Classification': label})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 读取数据路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_paths(train_crop_top_dir, test_crop_top_dir):\n",
    "    train_crop_top_paths = glob(os.path.join(train_crop_top_dir, '*.tif'))\n",
    "    test_crop_top_paths = glob(os.path.join(test_crop_top_dir, '*.tif'))\n",
    "\n",
    "    # 随机打乱训练数据\n",
    "    index = [m for m in range(len(train_crop_top_paths))]\n",
    "    random.shuffle(index)\n",
    "    train_crop_top_paths = np.array(train_crop_top_paths)[index]\n",
    "\n",
    "    print(index)\n",
    "    return train_crop_top_paths, test_crop_top_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 定义评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 9408        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256, 256, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 64) 4096        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 128, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 64) 36864       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, 128, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 256 16384       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 256 16384       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 256 1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 256 1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 256 0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 256 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 64) 16384       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128, 128, 64) 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 64) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 64) 36864       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128, 128, 64) 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128, 128, 64) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 128, 128, 256 16384       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128, 128, 256 1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, 128, 256 0           batch_normalization_8[0][0]      \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 128, 128, 256 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 128, 128, 64) 16384       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 128, 128, 64) 256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 128, 128, 64) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 128, 128, 64) 36864       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 128, 128, 64) 256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 128, 128, 64) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 128, 128, 256 16384       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 128, 128, 256 1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 128, 256 0           batch_normalization_11[0][0]     \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 128, 128, 256 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 128, 128 32768       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 128 512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 128, 128, 128 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 128)  147456      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 512)  65536       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 512)  131072      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 512)  2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 512)  0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 128)  65536       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 64, 64, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64, 64, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 128)  147456      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 64, 64, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 64, 64, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 512)  65536       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 512)  2048        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, 64, 512)  0           batch_normalization_18[0][0]     \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 64, 64, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 128)  65536       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 64, 64, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 128)  147456      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 64, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 64, 64, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 512)  65536       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 64, 512)  2048        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 64, 512)  0           batch_normalization_21[0][0]     \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 64, 64, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 128)  65536       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 64, 64, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 64, 64, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 128)  147456      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 64, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 64, 64, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 512)  65536       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 64, 64, 512)  2048        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 64, 64, 512)  0           batch_normalization_24[0][0]     \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 64, 64, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 64, 256)  131072      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 64, 64, 256)  1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 64, 64, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 256)  589824      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 256)  1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 256)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 1024) 262144      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 1024) 524288      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 1024) 4096        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 1024) 4096        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 1024) 0           batch_normalization_27[0][0]     \n",
      "                                                                 batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, 32, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 256)  262144      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 256)  589824      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 256)  1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 256)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 1024) 262144      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 1024) 4096        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 1024) 0           batch_normalization_31[0][0]     \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 32, 32, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 256)  262144      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 32, 32, 256)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 256)  589824      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 32, 256)  1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 32, 32, 256)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 1024) 262144      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 32, 32, 1024) 4096        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_34[0][0]     \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 32, 32, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 32, 32, 256)  262144      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 32, 32, 256)  1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 32, 32, 256)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 256)  589824      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 32, 32, 256)  1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 32, 32, 256)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 1024) 262144      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 32, 1024) 4096        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_37[0][0]     \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 32, 32, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 256)  262144      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 32, 32, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 32, 32, 256)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 256)  589824      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 32, 32, 256)  1024        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 32, 32, 256)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 32, 32, 1024) 262144      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 32, 32, 1024) 4096        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_40[0][0]     \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 32, 32, 256)  262144      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 32, 32, 256)  1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 32, 32, 256)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 32, 32, 256)  589824      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 32, 32, 256)  1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 32, 32, 256)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 32, 1024) 262144      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 32, 32, 1024) 4096        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_43[0][0]     \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 32, 32, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 32, 32, 256)  262144      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 32, 32, 256)  1024        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 32, 32, 256)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 32, 32, 256)  589824      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 32, 32, 256)  1024        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 32, 32, 256)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 32, 32, 1024) 262144      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 32, 32, 1024) 4096        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_46[0][0]     \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 32, 32, 1024) 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 32, 32, 256)  262144      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 32, 32, 256)  1024        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 32, 32, 256)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 32, 32, 256)  589824      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 32, 32, 256)  1024        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 32, 32, 256)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 32, 32, 1024) 262144      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 32, 32, 1024) 4096        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_49[0][0]     \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 32, 32, 1024) 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 32, 32, 256)  262144      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 32, 32, 256)  1024        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 32, 32, 256)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 32, 32, 256)  589824      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 32, 32, 256)  1024        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 32, 32, 256)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 32, 32, 1024) 262144      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 32, 32, 1024) 4096        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_52[0][0]     \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 32, 32, 1024) 0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 32, 32, 256)  262144      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 32, 32, 256)  1024        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 32, 32, 256)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 32, 32, 256)  589824      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 32, 32, 256)  1024        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 32, 32, 256)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 32, 32, 1024) 262144      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 32, 32, 1024) 4096        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_55[0][0]     \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 32, 32, 1024) 0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 32, 32, 256)  262144      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 32, 32, 256)  1024        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 32, 32, 256)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 32, 32, 256)  589824      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 32, 32, 256)  1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 32, 32, 256)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 32, 32, 1024) 262144      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 32, 32, 1024) 4096        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_58[0][0]     \n",
      "                                                                 activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 32, 32, 1024) 0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 32, 32, 256)  262144      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 32, 32, 256)  1024        conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 32, 32, 256)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 32, 32, 256)  589824      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 32, 32, 256)  1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 32, 32, 256)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 32, 32, 1024) 262144      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 32, 32, 1024) 4096        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_61[0][0]     \n",
      "                                                                 activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 32, 32, 1024) 0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 32, 32, 256)  262144      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 32, 32, 256)  1024        conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 32, 32, 256)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 32, 32, 256)  589824      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 32, 32, 256)  1024        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 32, 32, 256)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 32, 32, 1024) 262144      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 32, 32, 1024) 4096        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_64[0][0]     \n",
      "                                                                 activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 32, 32, 1024) 0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 32, 32, 256)  262144      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 32, 32, 256)  1024        conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 32, 32, 256)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 32, 32, 256)  589824      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 32, 32, 256)  1024        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 32, 32, 256)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 32, 32, 1024) 262144      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 32, 32, 1024) 4096        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_67[0][0]     \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 32, 32, 1024) 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 32, 32, 256)  262144      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 32, 32, 256)  1024        conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 32, 32, 256)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 32, 32, 256)  589824      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 32, 32, 256)  1024        conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 32, 32, 256)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 32, 32, 1024) 262144      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 32, 32, 1024) 4096        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_70[0][0]     \n",
      "                                                                 activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 32, 32, 1024) 0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 32, 32, 256)  262144      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 32, 32, 256)  1024        conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 32, 32, 256)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 32, 32, 256)  589824      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 32, 32, 256)  1024        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 32, 32, 256)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 32, 32, 1024) 262144      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 32, 32, 1024) 4096        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_73[0][0]     \n",
      "                                                                 activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 32, 32, 1024) 0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 32, 32, 256)  262144      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 32, 32, 256)  1024        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 32, 32, 256)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 32, 32, 256)  589824      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 32, 32, 256)  1024        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 32, 32, 256)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 32, 32, 1024) 262144      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 32, 32, 1024) 4096        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_76[0][0]     \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 32, 32, 1024) 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 32, 32, 256)  262144      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 32, 32, 256)  1024        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 32, 32, 256)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 32, 32, 256)  589824      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 32, 32, 256)  1024        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 32, 32, 256)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 32, 32, 1024) 262144      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 32, 32, 1024) 4096        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_79[0][0]     \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 32, 32, 1024) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 256)  262144      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 32, 32, 256)  1024        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 32, 32, 256)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 256)  589824      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 32, 32, 256)  1024        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 32, 32, 256)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 32, 32, 1024) 262144      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 32, 32, 1024) 4096        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_82[0][0]     \n",
      "                                                                 activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 32, 32, 1024) 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 32, 32, 256)  262144      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 32, 32, 256)  1024        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 32, 32, 256)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 32, 32, 256)  589824      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 32, 32, 256)  1024        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 32, 32, 256)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 32, 32, 1024) 262144      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 32, 32, 1024) 4096        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_85[0][0]     \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 32, 32, 1024) 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 32, 32, 256)  262144      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 32, 32, 256)  1024        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 32, 32, 256)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 32, 32, 256)  589824      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 32, 32, 256)  1024        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 32, 32, 256)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 32, 32, 1024) 262144      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 32, 32, 1024) 4096        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_88[0][0]     \n",
      "                                                                 activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 32, 32, 1024) 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 32, 32, 256)  262144      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 32, 32, 256)  1024        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 32, 32, 256)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 32, 32, 256)  589824      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 32, 32, 256)  1024        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 32, 32, 256)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 32, 32, 1024) 262144      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 32, 32, 1024) 4096        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_91[0][0]     \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 32, 32, 1024) 0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 32, 32, 256)  262144      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 32, 32, 256)  1024        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 32, 32, 256)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 32, 32, 256)  589824      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 32, 32, 256)  1024        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 32, 32, 256)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 32, 32, 1024) 262144      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 32, 32, 1024) 4096        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 32, 32, 1024) 0           batch_normalization_94[0][0]     \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 32, 32, 1024) 0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 32, 32, 512)  524288      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 32, 32, 512)  2048        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 32, 32, 512)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 16, 16, 512)  2359296     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 16, 16, 512)  2048        conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 16, 16, 512)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 16, 16, 2048) 1048576     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 16, 16, 2048) 2097152     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 16, 16, 2048) 8192        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 16, 16, 2048) 8192        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 16, 16, 2048) 0           batch_normalization_97[0][0]     \n",
      "                                                                 batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 16, 16, 2048) 0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 16, 16, 512)  1048576     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 16, 16, 512)  2048        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 16, 16, 512)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 512)  2359296     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 16, 16, 512)  2048        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 16, 16, 512)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 2048) 1048576     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 16, 16, 2048) 8192        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 16, 16, 2048) 0           batch_normalization_101[0][0]    \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 16, 16, 2048) 0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 512)  1048576     activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 16, 16, 512)  2048        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 16, 16, 512)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 512)  2359296     activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 16, 16, 512)  2048        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 16, 16, 512)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 2048) 1048576     activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 16, 16, 2048) 8192        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 16, 16, 2048) 0           batch_normalization_104[0][0]    \n",
      "                                                                 activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 2048) 0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 2048) 0           activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 32, 32, 1024) 8389632     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 32, 32, 1024) 4096        conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 32, 32, 1024) 0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 2048) 0           activation_91[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 32, 32, 1024) 18875392    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 32, 32, 1024) 4096        conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 32, 32, 1024) 0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 32, 32, 1024) 9438208     activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 32, 32, 1024) 4096        conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 32, 32, 1024) 0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 1024) 0           activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 64, 64, 512)  2097664     up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 64, 64, 512)  2048        conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 64, 64, 512)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 1024) 0           activation_22[0][0]              \n",
      "                                                                 activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 64, 64, 512)  4719104     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 64, 64, 512)  2048        conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 64, 64, 512)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 64, 64, 512)  2359808     activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 64, 64, 512)  2048        conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 64, 64, 512)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 512 0           activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 128, 128, 256 524544      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 128, 128, 256 1024        conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 128, 128, 256 0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 512 0           activation_10[0][0]              \n",
      "                                                                 activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 128, 128, 256 1179904     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 128, 128, 256 1024        conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 128, 128, 256 0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 128, 128, 256 590080      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 128, 128, 256 1024        conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 128, 128, 256 0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 256 0           activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 256, 256, 64) 65600       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 256, 256, 64) 256         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 256, 256, 64) 0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 128 0           activation_1[0][0]               \n",
      "                                                                 activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 256, 256, 64) 73792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 256, 256, 64) 256         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 256, 256, 64) 0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 256, 256, 64) 36928       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 256, 256, 64) 256         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 256, 256, 64) 0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 512, 512, 64) 0           activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 512, 512, 64) 16448       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 512, 512, 64) 256         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 512, 512, 64) 0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 512, 512, 64) 36928       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 512, 512, 64) 256         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 512, 512, 64) 0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 512, 512, 64) 36928       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 512, 512, 64) 256         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 512, 512, 64) 0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 512, 512, 5)  325         activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 512, 512, 5)  20          conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Classification (Activation)     (None, 512, 512, 5)  0           batch_normalization_120[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 91,069,849\n",
      "Trainable params: 90,952,975\n",
      "Non-trainable params: 116,874\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9305, 2499, 8336, 5291, 9173, 2167, 7187, 1080, 1664, 2770, 4750, 1238, 97, 5344, 9779, 5978, 7026, 6764, 1699, 4914, 6000, 8832, 301, 584, 7466, 7337, 4610, 3551, 10177, 262, 9074, 8591, 2532, 6936, 3089, 4233, 3296, 7008, 7859, 3222, 9645, 4834, 7655, 8809, 6416, 5251, 4882, 3249, 114, 7694, 8833, 2349, 118, 803, 1037, 7307, 3549, 8637, 1001, 8012, 1231, 523, 4401, 10110, 2237, 8639, 423, 57, 9623, 7121, 1095, 639, 3845, 7173, 5107, 6038, 1997, 9662, 7442, 9320, 3050, 7309, 3787, 4581, 2711, 544, 4234, 437, 2780, 9191, 2158, 8288, 10128, 7817, 7649, 9731, 4675, 6112, 9196, 5371, 10063, 8148, 6005, 5093, 7444, 3724, 6203, 900, 5097, 7676, 3539, 7454, 1206, 7807, 1678, 1721, 7391, 7939, 7512, 7418, 5744, 5338, 6150, 4993, 8763, 9379, 1761, 8063, 5573, 7944, 2041, 6085, 3536, 2093, 4486, 1644, 2801, 670, 9809, 6738, 3864, 9708, 9452, 6069, 5038, 5339, 5998, 9000, 2068, 7263, 2827, 5428, 6046, 3331, 9208, 1392, 3832, 6878, 8471, 6029, 6952, 2785, 10043, 8835, 1406, 1219, 4748, 1700, 8511, 5838, 5031, 2000, 7533, 6060, 4054, 651, 6236, 3184, 1451, 3916, 5772, 7482, 1092, 9389, 1806, 880, 5637, 6259, 3246, 9502, 8400, 1774, 4936, 64, 8234, 5477, 4490, 4126, 9319, 3067, 9871, 2839, 8501, 975, 7208, 481, 500, 5983, 6968, 3321, 394, 7349, 3582, 1286, 6704, 6138, 6331, 9373, 8563, 9348, 3501, 7703, 866, 5968, 4706, 151, 2473, 6177, 345, 4423, 4056, 4348, 2687, 6323, 3270, 7268, 8481, 3153, 1639, 9781, 6618, 6437, 8420, 907, 1718, 2149, 6792, 590, 2527, 462, 5839, 7396, 4971, 9479, 1349, 4273, 4756, 3060, 2716, 7488, 239, 657, 1385, 8965, 6488, 220, 3907, 2521, 7590, 9801, 2735, 7749, 1635, 399, 2324, 1742, 9391, 9864, 313, 3960, 2960, 2658, 10030, 5319, 7038, 6634, 1638, 8425, 2617, 5299, 3692, 4573, 3180, 10116, 7016, 3951, 6129, 9077, 5084, 1432, 7601, 2268, 8741, 9058, 5708, 8603, 466, 6999, 7246, 698, 9967, 950, 7122, 6023, 4801, 6844, 6737, 3979, 1965, 2315, 3830, 4495, 1371, 3090, 1985, 2728, 173, 2444, 6781, 5962, 3593, 5748, 6362, 391, 1263, 6460, 8806, 461, 1593, 3394, 2030, 1889, 3044, 1744, 5329, 2961, 8846, 5376, 309, 6037, 7164, 5363, 2714, 5050, 3014, 7299, 3244, 5921, 7613, 5913, 812, 4481, 3621, 7742, 8242, 6293, 2624, 5910, 1342, 3069, 2013, 8064, 10120, 8979, 5738, 9828, 3600, 3400, 10056, 7174, 709, 2488, 6025, 486, 779, 5067, 5764, 8135, 2870, 7559, 4177, 2080, 5767, 5290, 8712, 6995, 5661, 7833, 2169, 524, 1209, 3554, 2978, 7697, 4549, 4478, 5276, 2616, 9100, 7093, 4925, 5341, 8087, 2287, 134, 8788, 7735, 5656, 5626, 7938, 9744, 1317, 364, 8490, 674, 9106, 8353, 9540, 9067, 2416, 6855, 10069, 8739, 654, 3746, 5195, 3215, 4239, 2001, 7021, 2905, 550, 6015, 10094, 9567, 1315, 9917, 4363, 6676, 5387, 2493, 7231, 1914, 6812, 7452, 4644, 38, 1016, 6908, 4416, 8690, 5382, 7783, 6284, 7063, 5003, 2845, 5795, 3656, 2, 3301, 6628, 5482, 8321, 1108, 6415, 7515, 2052, 1203, 319, 7937, 2412, 2679, 9514, 8596, 3751, 6586, 1915, 9178, 7927, 7405, 318, 2043, 1401, 6173, 2413, 2049, 6506, 720, 8697, 6027, 3672, 8684, 3767, 9509, 4762, 8799, 2301, 703, 2475, 7417, 8680, 3611, 3921, 1484, 8668, 714, 5773, 731, 9892, 8800, 2662, 7269, 4248, 1148, 233, 155, 5625, 1097, 6024, 470, 1502, 6482, 4249, 3266, 5178, 5768, 6247, 7252, 2570, 6392, 6643, 3353, 8544, 782, 6389, 9175, 9611, 2476, 8224, 3860, 2391, 1115, 9016, 1597, 1520, 8427, 8554, 7701, 3313, 5570, 1221, 489, 7710, 6694, 9129, 6956, 6688, 8988, 5000, 8745, 4536, 9011, 1648, 3584, 8999, 3772, 5404, 7639, 3426, 10060, 5879, 7886, 3397, 9485, 8742, 3047, 2719, 5810, 9018, 1357, 8213, 9059, 980, 7503, 1197, 6730, 6520, 893, 8946, 9051, 8187, 5444, 7896, 6278, 1103, 475, 4704, 5697, 8474, 5854, 6524, 1637, 7765, 4280, 9965, 2984, 3098, 806, 4087, 10086, 43, 3819, 5036, 2290, 8822, 472, 8026, 8000, 5746, 5802, 4665, 4527, 4654, 1659, 2480, 9782, 5383, 543, 1929, 4461, 4119, 129, 6721, 2449, 4502, 34, 184, 8290, 372, 2926, 299, 8441, 5836, 4180, 2267, 6458, 7339, 2626, 1225, 7821, 7103, 9094, 7498, 2529, 8601, 546, 1556, 3517, 7778, 1934, 6942, 426, 7709, 7101, 449, 2821, 7474, 7227, 5975, 5045, 4395, 1003, 4067, 3034, 1040, 9734, 9704, 9962, 6631, 8665, 8781, 8972, 8448, 6063, 5275, 5397, 5137, 2170, 5500, 3892, 3282, 1271, 882, 3444, 6087, 6286, 8330, 821, 2965, 1982, 2028, 4213, 3275, 3803, 5463, 7563, 5958, 3401, 2328, 4821, 4373, 1107, 5866, 8528, 4999, 9004, 8212, 6924, 606, 8357, 4148, 4923, 2523, 2005, 3368, 4576, 5953, 7523, 7557, 1240, 5974, 7885, 8170, 6931, 4378, 3558, 3602, 5442, 8019, 5333, 3417, 1984, 9943, 8964, 6334, 5026, 354, 9233, 89, 3977, 5662, 3337, 3719, 1338, 5740, 1135, 6102, 4974, 4933, 7550, 7988, 8484, 443, 7690, 9352, 8046, 2753, 2936, 4121, 4476, 1449, 6110, 8838, 5010, 1279, 8931, 1065, 6265, 8194, 5679, 2572, 107, 5674, 2322, 10032, 1215, 597, 9099, 6061, 3490, 9586, 7946, 5172, 3481, 545, 3196, 8244, 9622, 5459, 1704, 5807, 1450, 7527, 9291, 282, 1745, 2150, 343, 7359, 5954, 3040, 8664, 8506, 8376, 7561, 10125, 6414, 8928, 4575, 5922, 3165, 2335, 5281, 2954, 100, 7152, 5791, 8295, 8534, 6211, 6651, 7081, 4776, 4585, 3036, 4063, 7747, 3649, 6218, 5247, 8994, 5527, 9332, 7989, 9551, 9590, 117, 1345, 9438, 5378, 2907, 2026, 760, 8413, 7671, 365, 5366, 3258, 1767, 2297, 7558, 10023, 2466, 3825, 6253, 808, 65, 269, 1255, 2082, 9867, 94, 5017, 8708, 6597, 8124, 5134, 7760, 3563, 1651, 589, 7641, 671, 8547, 5507, 8801, 6243, 9272, 10186, 9506, 6200, 2777, 8280, 2359, 2778, 7200, 3899, 9062, 5100, 6008, 5554, 9541, 3961, 9164, 7798, 8059, 7270, 2678, 1465, 7606, 5126, 8648, 2696, 2077, 9616, 3032, 915, 4458, 1019, 4295, 3001, 4007, 5385, 9924, 660, 6167, 916, 8236, 6985, 8802, 9470, 6116, 9991, 5441, 4068, 4501, 4858, 7281, 6763, 3250, 3486, 60, 9495, 3485, 4593, 5066, 7240, 2851, 581, 5447, 9302, 7494, 1952, 412, 2673, 8342, 1690, 5228, 678, 2249, 3694, 8371, 1832, 9180, 668, 2242, 9992, 6519, 2866, 2918, 9641, 9240, 4075, 9071, 944, 5981, 6001, 1212, 8047, 2546, 452, 7950, 8951, 9895, 9481, 1134, 3240, 1122, 2975, 7198, 1132, 1586, 8583, 7184, 7643, 1719, 2507, 5731, 7994, 7931, 4261, 227, 3836, 3842, 8151, 3058, 4219, 4101, 9436, 786, 675, 4300, 8079, 4912, 4505, 8465, 7463, 2203, 9222, 4761, 666, 725, 7863, 6607, 4287, 5307, 8260, 2752, 8952, 8069, 4540, 9533, 5696, 7640, 10101, 2135, 6406, 1284, 5712, 2165, 9172, 1848, 1577, 976, 502, 819, 2317, 4653, 4171, 4218, 434, 2890, 6423, 5301, 6903, 2116, 1663, 8073, 955, 9742, 5356, 3157, 8307, 4204, 1623, 5930, 4716, 10182, 1968, 251, 6321, 1557, 2140, 3624, 4517, 2332, 2722, 8794, 4157, 3413, 4658, 5393, 5919, 7933, 1256, 7046, 4650, 9823, 838, 2273, 9650, 5170, 3762, 1503, 8355, 10095, 5115, 6743, 4282, 6639, 5439, 2645, 9066, 5130, 8223, 3009, 9392, 1885, 947, 2537, 811, 9660, 2044, 1127, 2347, 1316, 4263, 6315, 4916, 2614, 5418, 5789, 1747, 4152, 9314, 3641, 3938, 9974, 7102, 7471, 673, 7569, 1779, 928, 4884, 3841, 7107, 9397, 9340, 9752, 9276, 6393, 360, 7761, 610, 1031, 9031, 1614, 4620, 6380, 8920, 6091, 6970, 408, 8221, 8658, 1855, 76, 4191, 8345, 6654, 1036, 6740, 6413, 9605, 3369, 9464, 1998, 6660, 140, 3294, 8986, 2898, 305, 6817, 848, 1610, 9297, 3768, 9507, 4676, 8408, 1136, 4127, 8163, 809, 2307, 887, 9458, 4755, 8388, 8507, 767, 4645, 7160, 858, 3610, 2671, 335, 636, 7328, 7608, 315, 3191, 6185, 4192, 6528, 1530, 5742, 6113, 5995, 2071, 9803, 1722, 2566, 6012, 1771, 6922, 9570, 8976, 1681, 3976, 5884, 10174, 6897, 10087, 8847, 8731, 3332, 2101, 2193, 9732, 3048, 645, 2489, 1482, 2875, 4662, 7340, 6418, 6309, 6500, 6557, 5498, 1842, 9212, 5154, 1365, 3765, 4608, 5691, 4005, 8954, 5035, 3019, 3122, 4153, 3525, 9125, 10002, 2741, 4595, 5471, 901, 5375, 1068, 2130, 6232, 6345, 8834, 753, 6041, 7693, 9256, 5550, 8917, 4929, 9795, 8868, 2403, 2420, 1121, 6678, 7777, 5592, 9764, 8343, 8265, 4357, 7583, 8433, 6715, 4601, 1045, 4909, 3373, 7135, 7027, 5729, 124, 839, 493, 4865, 3559, 8081, 50, 7286, 1253, 5885, 2897, 4679, 6485, 5187, 5039, 945, 7502, 7178, 4411, 7995, 10150, 9126, 10090, 4235, 832, 6033, 8380, 3931, 8884, 9692, 5308, 8112, 8543, 6479, 1581, 1265, 8053, 6895, 6074, 1740, 84, 5907, 7844, 5064, 8719, 7245, 4767, 8716, 3547, 108, 4109, 8387, 9678, 10114, 1064, 8803, 6365, 1218, 2429, 5190, 5351, 2221, 1100, 7607, 5901, 911, 2366, 7880, 662, 740, 3088, 738, 4350, 3075, 9552, 6446, 8667, 1828, 2108, 5445, 2114, 5517, 9187, 9216, 697, 8594, 4807, 1369, 6834, 5485, 6238, 6585, 2212, 4169, 7478, 7084, 8286, 9637, 1005, 1540, 8133, 6799, 3944, 6650, 2374, 2838, 1008, 1707, 3094, 8995, 3053, 2022, 51, 5413, 8996, 4917, 2180, 3545, 2699, 1258, 9527, 2132, 4736, 6778, 7368, 33, 10149, 231, 7119, 1876, 7788, 6230, 8880, 722, 5436, 692, 8607, 6741, 4913, 9471, 3155, 8604, 3638, 4429, 9979, 6768, 3919, 3763, 2595, 7248, 2243, 8666, 1803, 6311, 4747, 3138, 8941, 8414, 4808, 8611, 7555, 5224, 9333, 6784, 8158, 5081, 1590, 147, 4634, 2500, 9036, 9460, 2913, 5755, 2989, 3622, 3068, 1201, 9317, 4847, 3012, 8791, 1412, 5891, 9833, 2163, 5899, 4084, 8160, 6580, 1230, 5780, 8423, 9138, 2766, 8499, 1387, 3070, 4989, 9343, 7504, 4041, 6260, 396, 4861, 2804, 5327, 3167, 3750, 9130, 8722, 248, 4642, 3283, 7312, 5715, 8556, 7892, 8366, 1431, 5015, 9123, 9355, 2260, 1035, 9005, 9614, 4695, 3519, 7050, 5501, 6565, 5565, 5566, 6106, 2462, 9952, 875, 6591, 357, 5612, 193, 1408, 4542, 181, 6945, 2873, 10181, 2195, 6598, 9428, 6257, 2219, 5828, 216, 5141, 3774, 1416, 2692, 8934, 3177, 6420, 10000, 3399, 2914, 5194, 9856, 3914, 4372, 2345, 3091, 824, 1808, 10179, 6622, 8061, 7664, 2191, 2100, 5401, 2057, 1749, 586, 7571, 5893, 182, 7787, 2805, 5602, 4327, 629, 9486, 3855, 6275, 895, 421, 4303, 2173, 10016, 9602, 3197, 10003, 3461, 4246, 7905, 3555, 75, 5218, 6602, 3986, 7455, 1475, 4932, 1150, 8446, 9618, 2915, 9489, 7057, 5300, 2271, 9263, 1670, 2478, 3745, 8723, 10127, 6972, 4922, 2846, 7001, 5597, 2888, 10194, 4577, 561, 6099, 556, 1495, 6480, 6051, 5429, 290, 8577, 2398, 8071, 9519, 6231, 10145, 4894, 3660, 8512, 9876, 1616, 10147, 6261, 10104, 6648, 9972, 9755, 7393, 9626, 653, 5169, 2058, 1524, 4020, 9546, 626, 2782, 6288, 4019, 3518, 7167, 5487, 2647, 1341, 2216, 1800, 9921, 9535, 1646, 5938, 961, 5820, 6851, 3216, 1454, 9930, 2730, 576, 6672, 4292, 2137, 2404, 4135, 7753, 937, 6222, 614, 10051, 5946, 8509, 9738, 967, 4874, 310, 9825, 8292, 9713, 7458, 920, 2334, 8239, 8208, 2289, 1615, 9445, 5896, 4279, 5620, 3513, 4698, 8057, 8456, 3997, 5473, 5068, 1504, 2584, 616, 1491, 3901, 2737, 9441, 3290, 4689, 2535, 3407, 3452, 3457, 2063, 5959, 5704, 3338, 1307, 283, 5845, 4840, 1261, 9090, 8478, 2955, 9834, 6837, 6571, 4511, 6535, 286, 5449, 8368, 8317, 4437, 9927, 3851, 8095, 3305, 9534, 625, 9303, 5916, 96, 8660, 1716, 8956, 4851, 4103, 8155, 2580, 8777, 7644, 6881, 3042, 5233, 6845, 3441, 5574, 2909, 1390, 3885, 358, 6744, 3673, 4480, 8023, 4530, 1474, 7987, 8199, 6428, 6489, 3238, 5982, 1156, 10151, 6160, 7229, 6770, 7422, 4995, 787, 8344, 9189, 382, 9296, 7642, 5690, 3427, 9446, 7751, 7154, 6405, 3516, 6319, 4238, 3487, 8434, 4199, 2656, 9691, 8830, 6291, 10067, 8464, 1501, 3702, 5745, 5535, 984, 6098, 8861, 4380, 2601, 2807, 2568, 9288, 1969, 2232, 1759, 4082, 3896, 8653, 3738, 5706, 8279, 7315, 1529, 8896, 3625, 8298, 4682, 3512, 954, 6900, 4223, 8166, 3797, 4836, 5492, 9783, 8661, 9250, 9629, 8753, 4733, 8392, 2861, 7067, 8076, 7419, 4959, 1974, 3773, 99, 6148, 9878, 2613, 1957, 867, 8615, 1447, 1189, 1154, 4725, 1909, 3051, 1000, 593, 6699, 4685, 1598, 5024, 4831, 4332, 6122, 8839, 9953, 6127, 1493, 9329, 356, 1285, 8470, 6562, 7410, 7462, 6773, 1922, 9946, 5402, 9648, 8165, 5260, 9715, 5310, 7917, 4418, 6052, 762, 7659, 6459, 5205, 3248, 5018, 4, 9910, 8586, 10124, 2551, 1607, 1522, 8324, 860, 8410, 5833, 9565, 1537, 6911, 7970, 4216, 7176, 10119, 5262, 1821, 9028, 6281, 3963, 7055, 4354, 3880, 2312, 1276, 132, 4891, 7010, 2541, 2792, 4531, 3343, 405, 2982, 7319, 8659, 7610, 3224, 8346, 9466, 2669, 5569, 5069, 6202, 1576, 5532, 9357, 9442, 2239, 1017, 4829, 4044, 1235, 9223, 2590, 1723, 2670, 5284, 4906, 1787, 5718, 9739, 3665, 9232, 5806, 4038, 2065, 4328, 4637, 5490, 5944, 3789, 5079, 9499, 1936, 1140, 10028, 4285, 4342, 8738, 894, 8090, 3208, 2025, 380, 578, 8243, 5303, 6977, 2143, 6549, 1941, 6965, 4205, 4048, 8137, 5924, 5777, 2759, 7957, 5590, 3336, 2479, 4334, 8761, 4358, 6723, 4226, 8300, 2428, 9088, 4311, 5073, 9875, 6518, 8918, 9242, 5212, 7721, 9733, 5580, 2783, 5295, 8904, 5148, 7717, 7660, 1383, 2010, 5204, 9584, 785, 6336, 3066, 6432, 7317, 8438, 9575, 8329, 4703, 7609, 7638, 4790, 4071, 3552, 766, 1313, 1283, 322, 8173, 5211, 1363, 131, 4609, 6096, 1312, 2579, 2463, 4513, 4164, 4797, 3025, 9157, 8084, 4965, 7389, 10161, 4368, 1333, 1728, 4491, 1347, 1299, 5494, 7505, 777, 2604, 3923, 5680, 6494, 8857, 2985, 2994, 6947, 8419, 7372, 9132, 9837, 3419, 5875, 4299, 3854, 2576, 2186, 490, 5128, 7308, 9027, 3778, 7538, 569, 9169, 5197, 7306, 2148, 2318, 7276, 5759, 7304, 10059, 5754, 8250, 3345, 5586, 3312, 5720, 9014, 1764, 3255, 7073, 2916, 6978, 3642, 5103, 6864, 1266, 9293, 7708, 8955, 2999, 8617, 9262, 5852, 5830, 381, 363, 7529, 8340, 7080, 563, 5054, 2282, 7884, 3347, 991, 5434, 2362, 2294, 8232, 1402, 9612, 4591, 4138, 206, 3304, 4978, 2051, 9025, 2944, 7611, 7591, 5259, 5782, 9015, 9996, 1138, 10011, 1555, 8889, 8237, 276, 4250, 4618, 1151, 2075, 1609, 5792, 170, 3505, 2161, 2467, 5992, 7004, 3675, 5999, 9251, 8634, 432, 6118, 10113, 8891, 6376, 5608, 4095, 1048, 7772, 4106, 5345, 5288, 5412, 1834, 4845, 417, 10074, 5785, 1309, 6174, 1054, 1440, 7381, 2560, 213, 4091, 1014, 7920, 3130, 6453, 6871, 5587, 4558, 2756, 247, 5645, 7805, 10008, 1058, 5749, 2351, 700, 3272, 2808, 4652, 849, 2171, 756, 1047, 5044, 6109, 3802, 8762, 19, 3274, 2409, 6754, 4596, 2755, 8008, 2939, 4402, 9658, 7225, 4221, 341, 7871, 9553, 190, 1880, 4326, 994, 3135, 6034, 6920, 1932, 1694, 8807, 9432, 1513, 7736, 6385, 2200, 425, 1514, 1488, 2415, 6347, 9544, 5167, 2385, 4398, 1962, 6666, 5813, 3484, 1303, 5149, 285, 3856, 6481, 3026, 4841, 2300, 1860, 1458, 243, 7360, 4574, 8418, 7244, 1890, 8493, 2103, 3995, 1414, 7170, 6511, 7403, 4405, 3781, 924, 6582, 8460, 4729, 135, 4297, 7578, 5120, 346, 7716, 599, 1381, 5248, 8640, 1908, 178, 1093, 10180, 802, 3433, 10042, 4605, 823, 4339, 9419, 4915, 8406, 2511, 6018, 5043, 6663, 1629, 7431, 796, 711, 1421, 1798, 4343, 7168, 1575, 378, 7145, 10075, 7741, 4097, 1618, 3471, 4000, 5653, 8494, 8077, 8078, 4711, 1195, 8537, 3654, 6984, 350, 2400, 3567, 8216, 3771, 2292, 3590, 4457, 6123, 7928, 7129, 5617, 3770, 1827, 1437, 6806, 914, 5116, 6941, 9735, 1356, 6442, 3924, 2723, 7351, 337, 5599, 4568, 6912, 10001, 8268, 538, 7064, 1041, 8025, 612, 562, 3800, 5396, 7236, 5415, 395, 8771, 557, 7196, 801, 7873, 6169, 6491, 3606, 3041, 1378, 2557, 9280, 8759, 4022, 7750, 8360, 1665, 8021, 591, 8912, 4709, 7205, 4417, 7206, 7228, 9146, 8645, 1574, 2632, 7531, 6555, 8627, 6569, 2015, 2657, 1636, 242, 1583, 1, 1748, 5787, 1840, 2097, 3820, 814, 2394, 6146, 6702, 5530, 5935, 1289, 3915, 3285, 9522, 5643, 7888, 7385, 9295, 3061, 7450, 4516, 9105, 7943, 7737, 7634, 9069, 7186, 3998, 6786, 4939, 6795, 7768, 6525, 3169, 4832, 1571, 2643, 2018, 9982, 4888, 9988, 1104, 1234, 7553, 3497, 1245, 8389, 8479, 3423, 8502, 3634, 3113, 7022, 9370, 4881, 8131, 1145, 6640, 6728, 7475, 9144, 9989, 9642, 156, 5538, 8616, 21, 531, 2076, 5997, 2435, 6803, 665, 8993, 9300, 9843, 1380, 4141, 7599, 7678, 1630, 6461, 7543, 8852, 415, 7473, 1943, 3831, 6556, 9830, 5370, 209, 8197, 9583, 9315, 4131, 6011, 7731, 4293, 7912, 3596, 9266, 1178, 4867, 10071, 5799, 1633, 2266, 1015, 6522, 1606, 7763, 5426, 23, 3017, 2636, 4475, 3635, 8167, 7045, 5294, 2483, 162, 5326, 2204, 3581, 9019, 1160, 10088, 4442, 2874, 1895, 6216, 3697, 3424, 1149, 2762, 9591, 8002, 7499, 1824, 11, 5939, 5114, 972, 6923, 1324, 9160, 4222, 3297, 9718, 9176, 9247, 9613, 9462, 2526, 7110, 5614, 7658, 9480, 8018, 2372, 3870, 71, 8663, 7481, 7111, 3480, 6450, 435, 8051, 2544, 5576, 7033, 6512, 1536, 7291, 1706, 4667, 8516, 2087, 3446, 3314, 3817, 3543, 8094, 783, 5227, 4251, 8546, 2333, 6103, 6574, 1996, 4178, 7653, 4202, 210, 5451, 4559, 1325, 2105, 7169, 3359, 7264, 9421, 6789, 5394, 6735, 1971, 7852, 377, 6848, 2533, 6475, 9634, 5776, 7148, 4937, 8277, 9342, 3711, 2900, 5213, 5539, 2309, 8901, 2142, 5285, 9207, 741, 1229, 9879, 1426, 4241, 7535, 5811, 3829, 658, 985, 9270, 9893, 7661, 696, 1933, 8545, 451, 1579, 5876, 7700, 3099, 3162, 3325, 10146, 4396, 1320, 2354, 9459, 1900, 2650, 8633, 518, 1034, 6079, 6819, 2346, 5313, 3018, 2732, 3837, 9970, 3548, 532, 8539, 6299, 7997, 4009, 6840, 8457, 4510, 10035, 8206, 3439, 4926, 1346, 8416, 4968, 5825, 2115, 6929, 1920, 6687, 7858, 5274, 8404, 3875, 791, 7890, 1559, 4203, 4336, 5386, 1120, 7877, 1785, 3207, 9184, 4897, 5391, 8691, 6172, 1105, 2503, 9409, 1199, 5041, 2083, 9866, 4208, 8424, 5912, 4943, 3934, 8991, 4880, 275, 8386, 9395, 1220, 4112, 7232, 7926, 1294, 1548, 9045, 1620, 3987, 826, 311, 7265, 3105, 7035, 9855, 7285, 6056, 2264, 5440, 7014, 5688, 8862, 88, 5797, 5971, 6658, 3898, 479, 5466, 633, 9435, 2284, 7696, 3943, 3228, 3096, 1205, 8836, 5188, 8883, 3812, 4446, 3533, 4314, 7247, 4018, 8007, 7624, 1043, 1425, 1925, 2715, 978, 5730, 8127, 1086, 686, 2639, 4415, 1696, 10004, 3293, 10097, 4687, 7210, 4699, 1025, 6006, 7273, 332, 9890, 1389, 8555, 6268, 4752, 3700, 5855, 7311, 5469, 3945, 9652, 3081, 5456, 8335, 6164, 7855, 516, 9719, 5133, 7383, 514, 8177, 9649, 5878, 9633, 6020, 4185, 596, 4308, 9217, 3432, 6358, 2021, 6538, 4474, 4612, 3339, 82, 8186, 9559, 427, 6009, 9111, 4626, 7902, 8977, 2809, 4319, 2747, 3761, 2906, 7338, 8274, 2353, 5672, 6144, 2969, 9354, 8384, 3289, 2039, 2724, 6757, 8975, 303, 9844, 8903, 2547, 5623, 8466, 9065, 7962, 3140, 7743, 873, 6048, 10062, 3971, 861, 7602, 8643, 8227, 1671, 6716, 9639, 4136, 8367, 6647, 5146, 2484, 3783, 8266, 5504, 9881, 6656, 9170, 9412, 1851, 9112, 1976, 7326, 3008, 1182, 9006, 6697, 3821, 8720, 7579, 6729, 4518, 6070, 3411, 3570, 6156, 1680, 8642, 362, 7580, 3572, 3062, 758, 7015, 958, 3181, 9484, 9829, 410, 1354, 7728, 547, 6751, 7214, 3078, 8647, 929, 1448, 9134, 2382, 7438, 3790, 3430, 406, 2698, 2638, 2078, 419, 9793, 1516, 9349, 1945, 9290, 1462, 7909, 10046, 4930, 7932, 8314, 7575, 8538, 9687, 588, 6887, 1937, 2229, 5088, 5585, 3483, 1490, 3154, 5940, 7958, 3219, 8, 9287, 7125, 5390, 1192, 1611, 1903, 4298, 306, 1627, 3055, 885, 6566, 7479, 1674, 5520, 7031, 4151, 2627, 9926, 6682, 7507, 4144, 6324, 4969, 6017, 3731, 6349, 2665, 4830, 8447, 5774, 3164, 3085, 4492, 519, 2685, 4186, 8540, 6510, 7868, 5613, 7799, 6036, 3254, 6354, 8826, 669, 6629, 833, 4539, 9784, 6872, 5817, 2508, 6081, 5403, 2042, 2472, 4160, 1124, 8828, 2007, 7071, 9257, 7508, 5700, 8937, 903, 8792, 8134, 8325, 1967, 8251, 5072, 296, 7510, 9638, 7298, 6219, 5491, 8827, 6960, 7845, 1994, 754, 7146, 9942, 9870, 7251, 3170, 289, 9107, 10022, 4683, 4003, 37, 3562, 5014, 9745, 3806, 4713, 2966, 6910, 2325, 2769, 1805, 3323, 7302, 291, 8467, 1020, 3756, 9097, 4720, 2798, 8113, 8815, 728, 6914, 2356, 9209, 742, 3302, 6820, 3690, 5525, 8729, 4425, 6356, 6346, 6674, 1505, 1094, 4406, 804, 8503, 9017, 8527, 6854, 6134, 8948, 8333, 4988, 4963, 3470, 8656, 775, 6447, 646, 8241, 4142, 9677, 9802, 1083, 8146, 7734, 9040, 5989, 9775, 1435, 761, 7837, 5850, 10163, 2024, 6350, 3848, 5908, 5468, 7048, 2302, 8254, 9722, 4614, 4066, 5816, 7076, 931, 3964, 7012, 2559, 141, 4155, 8259, 1377, 1051, 5531, 3903, 9906, 62, 1032, 4548, 1161, 1849, 6435, 6813, 7099, 5914, 3651, 2606, 8439, 2575, 6843, 8899, 281, 4448, 7801, 9364, 8772, 5628, 20, 6246, 8381, 9841, 6062, 3416, 7848, 5002, 5801, 7941, 3346, 2991, 4436, 3897, 3627, 7619, 2425, 817, 7489, 7039, 9374, 9520, 8003, 4440, 1588, 4587, 3674, 1434, 1993, 7692, 1714, 6080, 8552, 2269, 1372, 7686, 2279, 6126, 8267, 9951, 8787, 2625, 6815, 7756, 730, 973, 4984, 121, 757, 1918, 4146, 6653, 6720, 4768, 2818, 693, 8445, 9269, 1864, 5111, 868, 6604, 8262, 10165, 6378, 2303, 2038, 6077, 9526, 9887, 699, 6830, 4301, 6989, 9400, 5843, 7221, 4150, 5145, 7853, 9741, 2524, 2234, 8816, 883, 1147, 3643, 1751, 409, 3027, 9874, 5840, 7421, 8369, 4580, 168, 9585, 6829, 1499, 4766, 1541, 263, 3437, 7086, 3607, 6551, 8362, 9298, 8526, 219, 872, 1594, 5209, 7272, 3173, 8649, 5588, 4770, 7509, 2667, 2120, 567, 9817, 5486, 7345, 232, 458, 774, 3994, 3648, 7416, 8599, 3968, 5705, 6296, 2144, 9285, 2768, 7541, 2707, 7468, 4283, 10079, 6957, 936, 3939, 7400, 1053, 4174, 8338, 9512, 456, 6188, 9353, 2653, 5077, 9186, 3422, 9029, 8230, 5979, 10117, 7262, 6341, 6440, 7151, 2390, 2924, 5654, 7536, 4777, 4389, 4102, 9968, 5246, 6377, 2693, 6644, 5488, 9928, 3396, 9381, 7241, 661, 9531, 7744, 2545, 778, 2765, 8120, 8733, 7043, 8468, 5934, 2817, 9089, 7238, 2498, 2713, 3383, 4680, 9997, 3566, 7818, 5837, 7065, 1928, 3188, 8562, 4482, 1239, 5104, 2098, 347, 3291, 1404, 917, 1766, 2350, 793, 1647, 3666, 4792, 7399, 737, 1781, 379, 5192, 154, 484, 5846, 7923, 7185, 9465, 5388, 152, 2003, 6861, 1007, 4730, 5822, 7077, 4374, 6338, 56, 5279, 7964, 6898, 338, 446, 2945, 8122, 4227, 5330, 4672, 769, 8933, 9561, 3615, 7862, 4244, 9963, 3730, 5132, 3538, 8595, 3695, 6785, 1770, 8111, 6170, 6998, 6626, 3230, 3385, 865, 4312, 4182, 9601, 8837, 3499, 3969, 3965, 1580, 6707, 9511, 7595, 9925, 2697, 4962, 2107, 2451, 1739, 9850, 9424, 1091, 3350, 4472, 7279, 7530, 9508, 385, 1109, 7384, 87, 8443, 2833, 1701, 1210, 2786, 7947, 1393, 3076, 2530, 789, 6124, 1601, 4529, 5516, 4991, 2812, 2375, 9472, 5555, 4347, 7354, 7800, 5750, 7864, 268, 6395, 3421, 6536, 9163, 5609, 6242, 7212, 10118, 3671, 9301, 773, 198, 9119, 7625, 1335, 5556, 2059, 1669, 1715, 535, 7897, 6184, 3039, 3515, 781, 7334, 7907, 3646, 10057, 7032, 7356, 5049, 179, 7013, 1208, 7062, 3262, 3389, 2725, 6636, 4184, 6495, 7746, 9433, 6503, 9569, 6363, 8204, 7132, 5406, 2259, 6885, 1859, 7648, 1060, 2855, 5025, 9148, 4454, 4428, 1930, 1353, 2124, 9070, 1924, 2407, 8458, 2326, 1978, 580, 6429, 7911, 5575, 2608, 9244, 7699, 1552, 9694, 6632, 7414, 10018, 6962, 4062, 6431, 5360, 6825, 9525, 7090, 186, 1963, 4024, 9281, 9174, 3544, 78, 2017, 4603, 3639, 9330, 9944, 3508, 1526, 2438, 1868, 127, 4466, 6044, 4118, 7832, 3534, 7409, 912, 732, 8960, 4941, 3889, 4214, 5624, 2781, 6838, 1898, 1396, 5082, 6959, 6373, 8065, 2329, 5784, 2127, 1617, 8853, 2927, 7441, 1711, 4281, 9671, 7120, 1688, 1796, 3011, 6245, 7803, 8584, 9321, 7480, 7522, 9167, 7113, 5414, 10025, 9131, 10021, 6889, 5632, 302, 7374, 7376, 5496, 9473, 8412, 7023, 7872, 9427, 54, 7024, 6133, 9985, 3269, 271, 5343, 6893, 1044, 8495, 6317, 3655, 9362, 2793, 8681, 2599, 2072, 6402, 4960, 414, 6927, 7365, 7542, 8359, 2355, 9853, 9161, 8679, 5886, 4743, 411, 1361, 6366, 7724, 5389, 5967, 9919, 8175, 1374, 3217, 3667, 9776, 1269, 3930, 90, 4660, 5320, 3788, 9121, 7282, 7822, 7283, 4096, 1438, 1734, 1445, 2036, 7230, 9043, 7371, 3588, 650, 3257, 3448, 6828, 9897, 348, 8409, 9493, 9955, 4331, 1430, 4464, 1666, 1649, 4524, 7924, 9420, 8881, 9918, 8677, 6147, 8103, 83, 3064, 9366, 8226, 3074, 7645, 2464, 7194, 6867, 3500, 2712, 3176, 9245, 5794, 1837, 2277, 367, 6775, 1330, 5354, 3807, 5407, 9468, 339, 4843, 137, 5882, 7495, 7294, 7420, 2689, 5022, 9902, 368, 8394, 9846, 3226, 6581, 3420, 9085, 4426, 2344, 3057, 807, 5605, 8497, 9426, 9767, 1650, 4117, 3735, 888, 1869, 4611, 5461, 8372, 6600, 2520, 5462, 5849, 4835, 3494, 3267, 5692, 4344, 3443, 1470, 2487, 6205, 8628, 4966, 1584, 2224, 9072, 7363, 1763, 8463, 7453, 6693, 4852, 549, 3900, 2446, 2369, 7469, 7691, 8893, 1439, 2027, 8521, 9202, 5618, 8282, 1720, 2806, 8548, 6189, 4080, 1223, 6132, 877, 2378, 9469, 5208, 6613, 582, 3586, 2972, 5898, 2136, 5547, 3445, 3867, 8726, 7144, 4849, 6040, 7182, 2659, 1621, 4500, 2474, 5278, 4356, 6473, 5503, 7190, 4788, 4274, 1444, 4309, 5888, 2256, 7562, 7425, 6256, 9044, 185, 10014, 7725, 3198, 3502, 8541, 1327, 4731, 9681, 22, 7622, 2006, 1441, 2750, 2734, 6374, 2262, 4643, 7361, 2482, 9949, 9857, 9931, 2853, 6067, 4061, 5273, 6769, 9387, 1207, 9712, 5229, 5857, 8257, 10185, 2784, 6119, 8411, 7552, 5372, 1829, 5309, 3478, 1397, 7069, 9609, 6949, 7127, 2336, 7209, 1057, 7005, 2794, 835, 4399, 7537, 9959, 8305, 5324, 8196, 5972, 10148, 6266, 3006, 245, 6621, 1497, 3079, 8256, 1566, 7059, 10041, 7386, 10072, 4557, 517, 403, 7584, 9958, 1033, 1695, 4514, 1507, 1251, 5823, 7940, 5162, 4659, 8036, 1891, 4783, 5040, 3455, 4069, 3107, 4088, 4161, 2631, 4471, 2206, 5432, 4259, 9912, 6583, 9697, 622, 5513, 948, 8320, 1485, 8624, 8646, 752, 5037, 5271, 10139, 3686, 2202, 3146, 6471, 9542, 9060, 3087, 9271, 9624, 7204, 4866, 2525, 4661, 7771, 6412, 9913, 837, 565, 659, 9785, 925, 8488, 1395, 7681, 10157, 8874, 2199, 1233, 10141, 7883, 7193, 3734, 3883, 10184, 1954, 5316, 6673, 6832, 5023, 5932, 344, 8879, 2174, 7323, 7548, 9081, 3468, 1456, 9210, 3341, 8536, 5220, 5231, 7460, 9765, 3705, 3791, 4050, 4855, 6747, 3962, 9383, 7436, 9278, 342, 551, 3408, 7451, 2802, 2086, 2986, 3601, 2962, 5711, 4684, 9179, 2215, 5727, 5699, 705, 8302, 9386, 3999, 1496, 1243, 4113, 9241, 4700, 7712, 1301, 218, 4008, 3418, 5094, 1254, 5969, 3330, 4908, 5906, 9751, 7492, 1907, 370, 2226, 8571, 10121, 4769, 9110, 9283, 7874, 7549, 1216, 10019, 7006, 2835, 9770, 8462, 7087, 9324, 6014, 5815, 2056, 2321, 4537, 3978, 9444, 3152, 1543, 10126, 4870, 6578, 7631, 4025, 4166, 105, 6168, 2110, 2440, 7088, 9153, 4105, 7305, 8935, 6237, 4896, 9200, 6314, 5317, 8942, 9311, 8531, 4002, 8398, 2820, 5568, 477, 9307, 6361, 9476, 4114, 2450, 676, 3785, 2828, 1291, 1260, 9676, 964, 8866, 2134, 4073, 5416, 3739, 4710, 4972, 7254, 2562, 822, 7348, 9248, 8963, 491, 6101, 4546, 2829, 8044, 3251, 5305, 3575, 7826, 4231, 890, 1463, 9213, 5976, 8097, 3645, 420, 1975, 7683, 3828, 7647, 8968, 3202, 2223, 9127, 4833, 3942, 6904, 4857, 272, 1112, 1765, 8285, 7070, 4944, 3349, 7519, 8235, 5196, 1486, 1428, 962, 6940, 7424, 3676, 869, 7412, 5232, 7870, 9095, 8482, 1822, 3459, 8625, 9152, 9724, 2746, 1183, 7289, 3827, 8966, 3381, 5827, 707, 9477, 9636, 4938, 3565, 2751, 4364, 4321, 989, 3975, 7954, 4085, 2597, 8698, 6031, 6269, 7547, 6149, 2553, 9998, 2884, 6452, 2494, 7257, 6035, 3033, 2964, 6691, 3335, 8854, 729, 9140, 5060, 2379, 6963, 8535, 6410, 8358, 5957, 2117, 6486, 3663, 6417, 49, 1072, 98, 530, 745, 3005, 2968, 5119, 6593, 4412, 5926, 160, 1196, 3727, 463, 9007, 520, 5419, 4828, 8750, 6588, 5758, 846, 1992, 1090, 560, 9467, 7003, 2261, 2258, 7828, 7195, 1267, 1884, 3097, 5665, 222, 2253, 7456, 9990, 488, 2361, 3863, 7322, 6307, 7112, 771, 8765, 7996, 8915, 304, 2811, 3935, 5280, 8566, 7255, 4375, 7260, 4848, 4305, 8974, 320, 6276, 4571, 2946, 1653, 5422, 9147, 9923, 7330, 1236, 7713, 9443, 2967, 4889, 1194, 4422, 6667, 6120, 3245, 8179, 723, 3137, 4487, 2457, 6075, 7250, 5409, 4077, 825, 10190, 9587, 10064, 3390, 1804, 3895, 9655, 571, 9275, 2308, 6948, 8746, 58, 2589, 1567, 4534, 10080, 1339, 8281, 8370, 9155, 6241, 7220, 6802, 8980, 6154, 6496, 2079, 2726, 7130, 1870, 7672, 3046, 4837, 508, 1489, 8522, 9571, 2655, 333, 241, 6271, 8911, 1768, 8098, 5258, 713, 3463, 4547, 5640, 7984, 9759, 2064, 8641, 5175, 6057, 119, 16, 4582, 8923, 640, 7486, 3477, 1046, 9211, 734, 4887, 9494, 2789, 7137, 6736, 7689, 9805, 9937, 8273, 7096, 7726, 6454, 3183, 1480, 8145, 3578, 6641, 2146, 5334, 3526, 3232, 4796, 2996, 6351, 7366, 7867, 3356, 6567, 7388, 314, 284, 495, 7115, 1939, 5046, 2214, 1693, 7108, 2048, 9092, 4386, 1568, 3929, 7358, 7630, 2840, 59, 8619, 8990, 10175, 1658, 8818, 3192, 2299, 689, 8961, 6509, 8524, 9994, 1813, 7556, 2352, 2141, 4322, 8784, 939, 3950, 8106, 31, 9010, 6333, 5603, 4064, 9239, 228, 3691, 1944, 6575, 575, 3144, 2567, 6422, 4485, 8459, 8892, 3355, 5322, 8841, 5887, 2646, 6016, 1871, 6199, 1703, 9647, 7397, 7301, 6427, 784, 165, 4742, 4154, 1705, 632, 6369, 5353, 8848, 9382, 2651, 6050, 8030, 9672, 1143, 2207, 5417, 8573, 863, 1599, 7597, 7540, 9415, 3300, 2112, 5630, 6599, 9402, 9573, 9150, 5545, 334, 1826, 5881, 2607, 7898, 4671, 8831, 5331, 3710, 3159, 4970, 4463, 9675, 8283, 2364, 878, 8200, 2904, 4004, 8882, 6950, 2035, 1687, 3709, 9401, 8902, 7335, 8289, 2217, 6761, 255, 3722, 6937, 4563, 9564, 5709, 9920, 6722, 2849, 2055, 5160, 9807, 1882, 5920, 2937, 2666, 8644, 7390, 79, 2727, 142, 15, 2577, 9204, 2002, 8271, 8597, 7804, 6853, 1708, 5671, 9249, 6058, 7398, 3592, 7171, 2814, 8780, 7249, 9049, 4165, 9860, 8921, 52, 10010, 9205, 4621, 7133, 6921, 2074, 870, 3474, 8713, 2205, 4803, 6255, 8981, 7952, 9393, 3911, 7680, 6684, 5950, 4267, 5824, 667, 10130, 5778, 4253, 6925, 1511, 1478, 2836, 5042, 5634, 2492, 9312, 7819, 3247, 5424, 4393, 8454, 511, 998, 6267, 2886, 2031, 583, 5765, 3150, 6198, 4260, 5942, 4323, 0, 7776, 5476, 4086, 4746, 772, 47, 1193, 3278, 2810, 2073, 5984, 9754, 4718, 3109, 5947, 4640, 9425, 7551, 9252, 4094, 4445, 2940, 5499, 1528, 9861, 6117, 2389, 2571, 7850, 3210, 5007, 577, 3810, 1817, 1702, 3498, 3573, 2386, 8308, 2469, 4236, 1816, 9885, 1063, 3333, 9102, 4351, 6906, 3891, 10115, 7720, 3307, 1088, 7472, 234, 4890, 2549, 592, 9665, 7802, 3409, 4604, 5890, 6882, 278, 4871, 3387, 820, 8067, 3905, 1762, 4838, 6531, 7795, 2995, 2423, 702, 5648, 3028, 3252, 1950, 2417, 7972, 8560, 7457, 8926, 1531, 3909, 9229, 1551, 3792, 4842, 7975, 1360, 5666, 3112, 9048, 2629, 1893, 4107, 7605, 1237, 9545, 3926, 9142, 10142, 6661, 8523, 6159, 8919, 4015, 2842, 3541, 4081, 8913, 6273, 9827, 2448, 3927, 1894, 6329, 7321, 6545, 1569, 4509, 3873, 5342, 4189, 8306, 1981, 6335, 1400, 687, 6938, 1273, 8183, 9238, 3808, 2832, 7219, 9568, 6, 3491, 1587, 6847, 1811, 5125, 5230, 1565, 4410, 6032, 2288, 5552, 5584, 3015, 4818, 5168, 5800, 5726, 436, 9973, 6816, 1077, 6724, 4567, 3371, 6709, 8125, 9706, 4674, 2763, 3182, 3223, 5856, 6220, 7320, 2168, 9999, 1164, 4705, 7051, 4976, 3941, 9384, 864, 7851, 9483, 6381, 6059, 5085, 428, 9948, 3377, 4179, 9012, 4291, 7041, 4039, 1843, 5756, 1187, 8810, 8724, 4773, 3527, 3564, 9260, 5652, 9606, 9341, 1874, 8378, 85, 6891, 2862, 9345, 7161, 9418, 3037, 521, 5505, 3861, 10012, 974, 4619, 4623, 6398, 941, 5217, 8682, 8093, 9788, 41, 9063, 9554, 3843, 8391, 6577, 46, 4515, 4708, 8760, 2797, 8293, 4985, 5105, 3259, 157, 7718, 2442, 4590, 109, 5606, 8496, 9358, 9334, 6468, 1002, 1631, 2092, 5677, 1375, 4538, 8263, 327, 9757, 4269, 7274, 621, 7303, 6777, 7598, 4754, 9743, 1838, 6886, 3204, 6210, 818, 10169, 7373, 4987, 7766, 1384, 8029, 2956, 2397, 189, 694, 6390, 9057, 3925, 158, 790, 4498, 554, 8855, 8178, 6809, 8812, 7278, 12, 1724, 7977, 10178, 3748, 1038, 336, 8870, 4850, 2436, 8587, 7394, 7423, 6788, 7223, 9563, 3869, 5028, 3881, 4798, 207, 4555, 7377, 1873, 7448, 9447, 9594, 6776, 9891, 496, 6918, 3492, 6100, 8517, 4488, 6698, 8795, 4335, 5725, 8736, 6430, 6108, 388, 4715, 9790, 10176, 983, 2744, 5340, 8310, 8688, 6071, 8865, 4997, 5509, 3488, 6540, 10015, 4554, 9086, 1980, 270, 4853, 938, 5030, 5055, 6967, 4042, 1562, 510, 447, 492, 7000, 163, 7767, 9128, 5495, 4919, 10137, 3402, 5127, 7380, 1155, 3161, 6462, 1446, 1460, 7429, 9746, 10082, 8361, 6550, 3393, 6791, 4268, 4430, 3988, 9610, 8650, 5219, 2564, 3591, 3133, 6204, 9390, 1492, 4434, 828, 9728, 2876, 17, 8192, 9318, 6875, 1792, 5814, 5936, 2742, 5283, 10191, 1521, 968, 7627, 9429, 2222, 6013, 9530, 7879, 6136, 10170, 2164, 1819, 3620, 373, 10152, 1262, 2061, 5102, 3212, 3728, 4738, 5479, 1232, 1966, 6404, 5071, 7217, 7344, 1752, 8442, 6297, 6810, 6097, 3723, 3858, 1411, 5518, 7175, 3887, 8449, 5467, 9214, 8549, 4484, 5350, 8936, 8480, 8689, 8140, 1362, 4079, 1129, 4924, 6383, 1902, 7715, 133, 1691, 2506, 5493, 2276, 1833, 8669, 1656, 10081, 5743, 683, 2620, 6868, 7079, 2603, 7525, 8375, 9159, 8486, 1515, 2125, 4953, 4749, 8885, 9786, 2628, 7670, 9422, 1457, 3415, 3352, 4240, 2683, 9797, 1334, 6477, 9957, 8189, 6905, 3231, 8820, 4190, 8055, 1913, 8347, 3466, 6508, 5923, 2513, 445, 1692, 8086, 9889, 9219, 4722, 1563, 8052, 1725, 842, 3449, 9577, 4616, 9052, 1791, 716, 6250, 2411, 8655, 4920, 3936, 8532, 3186, 10133, 7860, 9720, 5304, 8940, 1424, 8570, 1972, 169, 3522, 2825, 9651, 717, 8284, 471, 6360, 2192, 4494, 3045, 6988, 5526, 5741, 862, 4508, 5034, 4247, 1423, 8758, 552, 2201, 7341, 7426, 3082, 4666, 5321, 2733, 5714, 6186, 3213, 1049, 4220, 827, 1852, 6499, 8062, 4820, 5851, 2774, 6328, 6089, 2677, 5717, 4207, 6990, 1399, 7921, 1825, 4714, 8313, 4523, 664, 540, 8407, 400, 8858, 2773, 4800, 6252, 9524, 2934, 3826, 8261, 8352, 4589, 9886, 4310, 3151, 6807, 1152, 6224, 2815, 5669, 4728, 3838, 7838, 2145, 5557, 1042, 6913, 4252, 8907, 932, 630, 6076, 9448, 430, 7704, 8943, 515, 4092, 4656, 8510, 5478, 2004, 8297, 9947, 5076, 7036, 5673, 558, 8102, 5607, 3221, 10193, 5646, 6774, 5005, 9372, 4366, 718, 2623, 3680, 390, 6407, 5529, 3913, 9558, 1604, 6994, 5078, 3628, 2682, 4123, 3147, 10156, 1677, 4320, 1940, 4143, 101, 2865, 1277, 2899, 10047, 5544, 8702, 215, 6537, 9956, 2824, 5558, 4353, 6727, 3243, 4193, 6472, 7581, 6560, 2754, 1420, 1403, 7849, 2637, 7576, 5948, 2434, 5991, 7437, 8519, 6394, 1948, 8985, 1596, 879, 2447, 9872, 8233, 3613, 2491, 6576, 6359, 776, 3256, 404, 4854, 1405, 536, 8323, 9149, 8031, 2834, 5650, 4799, 9749, 8793, 4512, 8706, 7629, 4053, 9080, 14, 7843, 1990, 4187, 3769, 548, 9093, 3852, 2510, 3701, 7762, 1318, 871, 6030, 2419, 3010, 7432, 6765, 4898, 5453, 5435, 956, 10040, 1443, 4124, 4341, 9003, 4229, 2663, 5374, 5928, 8020, 7779, 2837, 816, 5925, 8873, 1118, 1612, 3835, 4886, 9845, 7673, 3967, 1469, 7861, 5235, 257, 7652, 2761, 8201, 8709, 7545, 1022, 67, 8089, 8949, 8797, 7028, 5433, 2104, 9158, 2050, 9087, 5835, 8205, 5990, 459, 4862, 8674, 8426, 7506, 7963, 10024, 5663, 3888, 1846, 6190, 8978, 10068, 5804, 1684, 2654, 6072, 780, 2622, 572, 2581, 6066, 4597, 5123, 9513, 1517, 9711, 1780, 9203, 2950, 9987, 4497, 1314, 317, 1087, 5249, 963, 6527, 7447, 7636, 4954, 8334, 8016, 2852, 1553, 148, 3467, 1755, 195, 5106, 9133, 2155, 6745, 986, 5572, 7973, 300, 8824, 3794, 3970, 6665, 4137, 1009, 3194, 3603, 7789, 9405, 1174, 10037, 3579, 3128, 9543, 5408, 4721, 3659, 1923, 8530, 1591, 8401, 8629, 2368, 691, 6419, 507, 1983, 4001, 8085, 9950, 7157, 7618, 2694, 9463, 7695, 5122, 280, 5763, 1592, 3493, 4023, 8013, 644, 3743, 6733, 6022, 5011, 2066, 8957, 9313, 5732, 2588, 5411, 7491, 5945, 4677, 526, 2387, 2857, 1082, 6805, 4277, 150, 9740, 6659, 9941, 6304, 9940, 8349, 1973, 8117, 8301, 6426, 4194, 7126, 1657, 4453, 2285, 225, 6797, 6289, 513, 1111, 10038, 6121, 2831, 9813, 943, 6919, 8929, 7969, 533, 6254, 648, 1679, 10084, 982, 7296, 5256, 534, 5255, 9654, 3685, 1862, 4108, 4330, 2822, 7831, 10109, 9078, 7485, 5583, 3103, 6530, 3004, 6234, 4678, 6449, 8767, 7810, 6971, 8144, 4256, 5062, 1951, 1137, 2951, 6808, 10092, 10049, 4638, 2534, 2971, 2210, 1173, 8717, 6559, 1626, 5171, 3717, 6669, 3453, 7702, 5629, 1935, 2561, 9880, 2970, 2672, 6082, 9700, 4370, 1417, 6095, 2257, 9117, 9181, 5237, 5985, 27, 2988, 6229, 8498, 9774, 4443, 8631, 5359, 5058, 1226, 6258, 3295, 851, 122, 9598, 1359, 6719, 6318, 1089, 7147, 2432, 6982, 9521, 223, 80, 3460, 8291, 1141, 7007, 6155, 9599, 2974, 8553, 369, 4031, 637, 4237, 2767, 3083, 1459, 5051, 9328, 8390, 8515, 2196, 5533, 910, 1176, 4646, 2194, 2220, 4338, 8377, 7620, 3984, 4812, 6207, 7739, 3529, 2396, 5052, 6760, 2676, 3959, 6780, 7347, 7094, 5139, 6554, 5719, 112, 5165, 1179, 4532, 5707, 2578, 6166, 8869, 264, 279, 6042, 8001, 9619, 3464, 9532, 3847, 5591, 5965, 9862, 1535, 8278, 9, 7141, 5880, 3609, 4813, 6111, 8040, 2331, 9557, 8309, 3849, 9556, 4167, 6997, 9034, 3799, 4209, 6876, 8700, 8207, 4337, 9038, 1628, 1268, 6969, 1946, 81, 7887, 3125, 1004, 3268, 6701, 5206, 1883, 5410, 2977, 7443, 4691, 6630, 7752, 1061, 8500, 7526, 10077, 9617, 1275, 1410, 4617, 5933, 6274, 3148, 10132, 7603, 5615, 5, 5242, 2706, 1130, 5020, 1888, 9936, 6677, 8704, 1296, 8987, 115, 2931, 7271, 1066, 8109, 2151, 8327, 9778, 3308, 9154, 7484, 10099, 1602, 3101, 2563, 3834, 3149, 2795, 830, 5057, 2893, 2803, 618, 3585, 7546, 8605, 2238, 2703, 1642, 9995, 7820, 3279, 3623, 8005, 5108, 3203, 7497, 8128, 5676, 7684, 235, 8703, 6652, 6601, 4397, 6523, 4918, 5287, 2045, 3882, 4360, 6039, 4863, 1114, 4032, 1697, 899, 2421, 4346, 4552, 3320, 5757, 246, 3132, 7166, 8774, 9371, 3056, 4663, 3435, 1901, 8840, 6490, 2091, 8598, 4483, 4040, 3871, 9922, 2760, 8876, 7904, 9151, 8908, 2298, 913, 464, 6225, 4276, 4266, 3741, 6800, 1477, 1564, 813, 836, 7666, 8116, 5053, 8557, 3782, 4635, 188, 386, 4427, 656, 2979, 203, 4304, 7588, 8126, 2454, 7570, 9439, 9832, 744, 7496, 5871, 9932, 9299, 3687, 3454, 5475, 4120, 2519, 2649, 7287, 1322, 3316, 7793, 539, 2147, 8248, 1727, 4876, 438, 93, 1506, 799, 5223, 797, 2166, 7922, 3716, 9197, 3370, 10073, 6796, 7842, 6312, 2878, 455, 8169, 8341, 6162, 9835, 7142, 5099, 4670, 4771, 7277, 845, 2864, 6748, 4702, 9198, 6055, 6153, 4651, 9139, 3733, 7840, 3561, 4033, 226, 8672, 9261, 9536, 1672, 3703, 4070, 8871, 6543, 2376, 4949, 9218, 9316, 4780, 9555, 5481, 2644, 905, 9589, 7705, 9883, 4822, 2320, 1328, 2486, 4804, 5769, 5332, 3521, 5063, 8037, 6399, 4359, 501, 3022, 685, 5760, 8154, 5191, 10129, 6981, 997, 6484, 8992, 969, 4696, 5355, 9787, 9688, 5682, 1280, 7367, 9820, 8686, 5894, 9762, 4544, 6178, 4242, 7796, 441, 10031, 6043, 144, 6532, 7109, 1942, 6915, 2245, 7836, 9282, 9939, 2095, 2461, 3583, 6165, 9453, 2094, 8238, 4996, 5296, 6783, 4503, 3063, 5514, 8927, 8585, 128, 5631, 9221, 9826, 6492, 8514, 2456, 8211, 9166, 4296, 8888, 194, 6611, 120, 2992, 3818, 1415, 1731, 5788, 2286, 3374, 655, 9068, 3682, 3947, 8743, 9693, 4504, 1224, 4630, 5596, 4982, 1603, 5917, 2363, 3327, 2856, 6295, 5182, 353, 2993, 7300, 1075, 3614, 7092, 3110, 8311, 5892, 6408, 5244, 1442, 859, 7824, 8222, 2592, 7011, 2771, 9501, 7978, 3683, 5988, 1144, 9794, 6926, 6302, 3636, 3104, 1512, 4781, 2610, 2384, 480, 6726, 5693, 5636, 2867, 9350, 8572, 2235, 7261, 8452, 10131, 2441, 8906, 6804, 2188, 988, 1823, 9346, 2539, 7662, 4469, 8953, 9492, 5762, 6664, 6424, 1938, 4265, 7314, 2012, 3510, 4006, 5261, 5140, 8890, 6541, 187, 2957, 1989, 7243, 5809, 5689, 7727, 4181, 9644, 9966, 6714, 3520, 5619, 1427, 2477, 2990, 5735, 2518, 42, 8654, 5685, 8779, 2621, 719, 8748, 1311, 3209, 4090, 2717, 8561, 3605, 5225, 7999, 13, 1867, 1550, 253, 8080, 3718, 1336, 3386, 6608, 8228, 9487, 7355, 677, 3758, 2247, 200, 7378, 9013, 9625, 3677, 4624, 5956, 5528, 7587, 8789, 5980, 4628, 3271, 9309, 5147, 9041, 2084, 256, 5008, 8215, 2248, 750, 6858, 1340, 6561, 7967, 3007, 2126, 10061, 2800, 6883, 6603, 8068, 2184, 2522, 3780, 930, 2470, 6403, 5323, 6425, 8255, 4940, 3902, 844, 5369, 5966, 8153, 2252, 6609, 265, 1028, 4391, 4225, 3357, 2153, 9615, 9001, 460, 795, 3100, 7284, 8190, 4693, 6739, 2358, 202, 10005, 1422, 1772, 183, 39, 600, 287, 2642, 4551, 5221, 9277, 8778, 3190, 1386, 8435, 7082, 9538, 4911, 2543, 2427, 10112, 2550, 7037, 8559, 6466, 9237, 8337, 1126, 647, 4994, 1169, 6515, 794, 2373, 726, 3608, 4794, 18, 2872, 4955, 7203, 2402, 9901, 5710, 7894, 2316, 6400, 6176, 8403, 3030, 3318, 24, 5524, 10078, 498, 4592, 2263, 4816, 7156, 1073, 1958, 1878, 8269, 3185, 9491, 8694, 2871, 9194, 2959, 6572, 8673, 10085, 5931, 469, 7985, 1252, 9327, 881, 5739, 4387, 1931, 3309, 4057, 7237, 9478, 8304, 2343, 1211, 2512, 3214, 3514, 7375, 4499, 5226, 9120, 9838, 9230, 6888, 3617, 1184, 3696, 9308, 6339, 8415, 204, 5183, 1508, 465, 8962, 9188, 5897, 8718, 1741, 9461, 9220, 8922, 2296, 5458, 2502, 3016, 2538, 8574, 3866, 6790, 1709, 8162, 205, 6756, 4758, 1376, 5346, 10158, 8198, 1799, 2903, 9377, 1906, 7865, 960, 254, 8253, 5070, 7177, 4361, 2573, 6902, 2925, 3462, 9682, 5090, 5012, 4272, 4438, 857, 5365, 2776, 10138, 1379, 2605, 3637, 4928, 4043, 5667, 6513, 4455, 7370, 10136, 1778, 3260, 1069, 1831, 8636, 800, 2190, 6579, 3052, 7623, 2635, 196, 9854, 8299, 7226, 4945, 1784, 3796, 240, 1101, 9848, 2313, 7516, 4948, 5027, 2901, 1332, 9705, 3358, 6264, 4100, 7518, 9836, 7446, 1986, 7316, 2183, 2540, 8699, 4271, 512, 3440, 9717, 4545, 4037, 9082, 906, 4648, 4507, 1726, 8328, 9668, 1200, 680, 6975, 3653, 9394, 9404, 1117, 9457, 5292, 3755, 4526, 3661, 10048, 3805, 605, 7411, 8139, 5357, 7780, 8004, 4973, 5312, 8864, 6386, 4385, 1466, 8188, 6662, 8422, 139, 6294, 6396, 1310, 6685, 9323, 8564, 6547, 8529, 2090, 5686, 4975, 1753, 3284, 4496, 8768, 3956, 8469, 8944, 8707, 3721, 5325, 7656, 68, 5753, 1030, 8671, 5381, 6391, 172, 7331, 1433, 30, 2029, 8905, 7564, 2231, 6570, 1467, 6992, 2280, 9986, 4550, 3766, 9259, 8054, 9246, 4602, 7740, 5519, 9975, 4158, 166, 5973, 2531, 1995, 2254, 5216, 7395, 4522, 8898, 5664, 3187, 7256, 8735, 4795, 1736, 1272, 1023, 6979, 8925, 2310, 8483, 5842, 9075, 755, 9304, 7965, 4688, 5560, 9498, 4243, 4951, 4028, 2848, 5016, 2941, 892, 6433, 2880, 6280, 230, 7042, 3273, 10135, 266, 2854, 3405, 3237, 2908, 3175, 375, 1287, 6337, 442, 8451, 9061, 3163, 2819, 9773, 8220, 10187, 267, 8430, 10007, 6107, 3354, 244, 3904, 5250, 3823, 8385, 1879, 1274, 6623, 8010, 4257, 3989, 9165, 9363, 6313, 3126, 2128, 5996, 2377, 1308, 594, 876, 1139, 4900, 4655, 407, 8692, 6217, 5210, 9215, 5185, 4467, 2569, 9504, 6587, 424, 1713, 509, 9050, 3086, 2311, 7560, 61, 1248, 4197, 6019, 7759, 6287, 9515, 3886, 1519, 9206, 1123, 7404, 2681, 2619, 2980, 9497, 715, 5236, 7908, 8432, 7140, 8182, 6839, 1018, 5955, 3804, 4787, 4817, 6771, 8294, 3670, 9410, 4588, 8245, 8436, 5457, 6002, 433, 1953, 2230, 3865, 6633, 1180, 8878, 3168, 7521, 1775, 4060, 1673, 3206, 9898, 7362, 8249, 3106, 1217, 8264, 8405, 1561, 9574, 4104, 9396, 2008, 4383, 8805, 3726, 9821, 7150, 4964, 1116, 7706, 9911, 3982, 6301, 3344, 2739, 6384, 5747, 2085, 1919, 6553, 5180, 7019, 4579, 5929, 9796, 9360, 8844, 3363, 5253, 5805, 2399, 3535, 9840, 4778, 3334, 7979, 620, 3482, 1304, 5398, 3668, 891, 8164, 1844, 3367, 7667, 3992, 7980, 1856, 2187, 4477, 6507, 5598, 9226, 979, 3475, 2270, 4195, 7986, 7593, 9977, 2997, 3957, 3395, 5521, 3553, 6690, 643, 1845, 3632, 6696, 3560, 1712, 2410, 1949, 3178, 4173, 70, 9935, 2337, 7813, 7511, 7234, 5121, 6822, 9243, 8737, 138, 2788, 9416, 6935, 8472, 9451, 6987, 483, 6986, 8225, 6645, 8118, 145, 9523, 4459, 2704, 9815, 5430, 2471, 6711, 5874, 5289, 6283, 1468, 8606, 1625, 3388, 9430, 9896, 10055, 2668, 8365, 9699, 392, 5156, 3366, 6934, 4462, 902, 5392, 8520, 7635, 9730, 398, 8011, 8374, 6615, 3145, 5472, 1074, 7949, 2054, 6680, 74, 704, 8287, 3736, 8938, 9560, 7961, 7162, 384, 4168, 9053, 8461, 316, 6590, 5577, 3679, 7053, 4307, 5264, 7589, 1814, 3626, 7445, 3688, 3410, 7675, 8872, 1039, 10106, 2919, 4629, 3172, 5013, 6493, 8272, 7487, 1917, 36, 3813, 2458, 5454, 7500, 522, 1113, 6749, 9450, 1344, 9539, 9331, 7428, 541, 4892, 217, 9595, 7068, 1056, 3000, 8813, 10098, 349, 6270, 1257, 331, 467, 1542, 6870, 8786, 5277, 690, 1471, 886, 6594, 2998, 6372, 2688, 9905, 4578, 1305, 634, 6831, 1760, 1905, 4116, 208, 221, 4735, 8525, 701, 6695, 8161, 6397, 4065, 6782, 164, 6874, 450, 7153, 5716, 2868, 4717, 9761, 9168, 5124, 9413, 4921, 9810, 8096, 1926, 2037, 328, 7811, 940, 3678, 325, 5086, 6552, 1382, 9907, 6221, 1685, 6502, 7935, 1078, 6470, 3874, 3265, 649, 9696, 3003, 4170, 3595, 9083, 4521, 6364, 25, 3658, 9231, 8533, 5384, 7781, 898, 3744, 6514, 3650, 743, 5600, 3932, 8612, 5446, 3793, 4027, 9596, 6368, 8477, 6841, 3054, 1622, 7191, 1661, 8043, 5642, 7098, 7816, 1573, 8107, 2109, 1964, 2708, 2218, 7755, 1589, 10093, 9877, 9141, 9768, 6021, 9292, 3414, 8193, 2046, 9537, 5808, 3894, 7791, 4569, 295, 10034, 6901, 8104, 3298, 9716, 6131, 8429, 7382, 1027, 9265, 5464, 2729, 10188, 249, 422, 171, 3574, 2426, 3195, 5536, 7056, 7258, 6214, 1464, 3784, 4957, 8231, 3576, 6596, 7925, 5523, 7971, 5551, 6443, 2081, 2554, 748, 7402, 9286, 949, 5348, 2548, 8695, 9403, 8049, 4139, 10089, 7568, 3752, 5048, 834, 9726, 4583, 149, 1738, 3242, 2787, 6342, 4026, 2370, 7707, 8567, 8203, 9903, 9096, 8258, 3092, 73, 805, 585, 3757, 6409, 8150, 4935, 765, 1732, 1886, 6045, 167, 8202, 6592, 746, 7266, 2241, 3384, 8894, 6191, 5450, 2453, 9701, 3095, 542, 1162, 8152, 9336, 8916, 4525, 4130, 5021, 4017, 6152, 8296, 9035, 5438, 3949, 125, 6991, 444, 1683, 174, 3049, 7632, 8821, 1786, 224, 397, 2591, 4986, 7983, 6710, 7155, 7903, 7825, 3378, 2556, 8845, 5861, 3503, 1419, 8074, 5425, 1750, 9789, 482, 7336, 5987, 201, 3853, 8618, 7044, 8171, 6004, 8662, 6457, 6104, 1319, 8382, 3589, 6826, 10108, 7651, 3469, 5263, 9780, 4759, 7233, 3193, 10134, 4632, 3556, 4074, 642, 6955, 4765, 8711, 8136, 2593, 8608, 9454, 2460, 6856, 1343, 374, 7325, 603, 2154, 5443, 6717, 527, 8579, 9054, 9322, 1987, 4598, 8747, 4732, 376, 5994, 7951, 1970, 9518, 7600, 1872, 909, 6814, 8217, 9073, 2684, 3131, 3174, 9310, 5834, 9981, 5431, 5096, 7876, 214, 2585, 2885, 2565, 4290, 1321, 7181, 9455, 3706, 4125, 5144, 9023, 3954, 8099, 4245, 1214, 4977, 5240, 10029, 9024, 2395, 4433, 4784, 3235, 5508, 5293, 4128, 8843, 7353, 4802, 3189, 1364, 7275, 2305, 3742, 2265, 1866, 4669, 8092, 721, 5006, 9528, 9632, 10045, 5841, 5698, 5941, 9496, 63, 7775, 10052, 8775, 4045, 6890, 5358, 9969, 2496, 8379, 4420, 4111, 553, 749, 7916, 2011, 5703, 1600, 9686, 2430, 4902, 8363, 1947, 2879, 4786, 7392, 261, 1794, 6670, 457, 3072, 4115, 8715, 5483, 3292, 5161, 4740, 3504, 9104, 8056, 1146, 9763, 5315, 5793, 6448, 8006, 6505, 8075, 770, 9798, 2062, 627, 1298, 9407, 6946, 6679, 3833, 9482, 5193, 3507, 7990, 2244, 3340, 1533, 706, 10033, 10020, 4613, 587, 977, 2516, 5245, 4376, 2745, 768, 8945, 4805, 5694, 7030, 9592, 9769, 6130, 9399, 2406, 10143, 7318, 4306, 6614, 7066, 1910, 1288, 4340, 8766, 555, 2159, 8989, 6444, 9582, 329, 7085, 2319, 1076, 9171, 724, 5943, 5721, 3236, 7242, 1746, 829, 8130, 609, 6047, 2847, 6627, 10159, 5297, 3532, 4400, 8041, 5452, 4479, 5153, 10173, 4424, 6213, 5423, 2392, 8428, 4998, 2327, 9627, 9055, 884, 5455, 1329, 8191, 6223, 3991, 9753, 9224, 6811, 5267, 9325, 9385, 2033, 2338, 9449, 10006, 733, 7189, 5848, 6894, 3023, 1776, 3983, 6742, 7577, 3795, 1839, 8088, 5361, 7974, 4046, 7465, 9819, 2422, 2339, 2609, 933, 672, 10107, 5616, 3361, 8147, 4049, 3918, 9714, 6916, 8626, 2040, 44, 2009, 1300, 7945, 9294, 175, 6833, 8508, 1106, 1241, 7669, 3317, 7981, 735, 1881, 5589, 8185, 9039, 7723, 4692, 355, 608, 4286, 2841, 7633, 3981, 3205, 810, 6944, 8728, 8886, 5858, 2863, 7123, 8939, 2178, 9579, 2758, 8638, 5150, 6474, 1247, 9869, 7427, 7517, 1847, 3597, 6300, 6899, 7018, 6128, 9631, 3523, 7180, 3124, 8149, 2250, 55, 9369, 7293, 5129, 2920, 7614, 9839, 5101, 5158, 5911, 2246, 9037, 5668, 4967, 1737, 5786, 8670, 8969, 308, 440, 6766, 9721, 2816, 4198, 9818, 476, 7072, 4690, 4110, 1436, 4599, 32, 5638, 5118, 3438, 2179, 9326, 4379, 1142, 4318, 3811, 7163, 1956, 1865, 7895, 6382, 8613, 7687, 6750, 6954, 3689, 6083, 6958, 2209, 3779, 3953, 448, 9359, 1509, 5877, 6718, 896, 3568, 9766, 5083, 1472, 9431, 3450, 840, 1487, 6151, 3447, 8024, 2922, 3021, 8740, 6158, 2775, 3382, 9799, 1605, 3114, 2069, 2705, 3577, 7854, 1668, 9915, 3472, 9162, 6993, 292, 3798, 3002, 5155, 8518, 9865, 7901, 4444, 3729, 4175, 5061, 6953, 3868, 7435, 8959, 8318, 2911, 1991, 942, 9971, 1358, 4873, 9578, 5074, 9529, 5977, 7594, 2468, 4408, 8971, 5960, 8210, 8859, 3879, 1188, 5268, 6521, 9635, 8014, 8123, 4779, 7654, 3537, 1904, 9079, 3276, 2433, 2360, 6762, 1098, 9646, 3693, 5176, 352, 2152, 3708, 3403, 1259, 8138, 4562, 4047, 7847, 8609, 1877, 1955, 7785, 6411, 2381, 7829, 4013, 1892, 8710, 3657, 6115, 192, 6879, 2228, 7105, 2948, 5109, 5781, 7764, 688, 6187, 5318, 3143, 3633, 5853, 2505, 1167, 9934, 9368, 5400, 7165, 8849, 3747, 5502, 5511, 682, 8576, 2341, 628, 2860, 1366, 7459, 6476, 4958, 8035, 8319, 889, 9344, 180, 9103, 4317, 10155, 6517, 8947, 10039, 736, 2383, 4627, 2691, 613, 1250, 10153, 788, 197, 10066, 8393, 971, 2342, 6624, 8476, 9669, 3115, 4201, 6343, 4586, 4723, 7207, 3134, 5594, 6263, 9566, 2340, 4726, 4907, 4254, 564, 9607, 5651, 8110, 4883, 4036, 4159, 7834, 6375, 2799, 8399, 8924, 6464, 8749, 663, 8804, 8105, 7782, 990, 8575, 4211, 9698, 4382, 8764, 9517, 9550, 3059, 10013, 4872, 9640, 6320, 2574, 3479, 3776, 7688, 6436, 1052, 3120, 9284, 9777, 146, 1085, 5683, 6734, 4864, 6606, 5179, 497, 1081, 9398, 6456, 5681, 992, 2701, 5657, 4904, 6310, 5553, 8621, 6605, 1455, 8141, 6197, 3031, 6846, 1157, 3530, 7461, 3489, 2883, 1278, 8856, 4016, 7839, 298, 3857, 4315, 5131, 5311, 5601, 4570, 4052, 8757, 6732, 494, 7329, 8676, 2882, 4719, 199, 5902, 1729, 2047, 6824, 3815, 3123, 6966, 5465, 2943, 1841, 7809, 8009, 6249, 4147, 3233, 4753, 8444, 5489, 1204, 2281, 611, 1249, 7711, 2935, 5199, 3618, 8101, 2843, 5272, 6206, 6248, 7017, 3839, 402, 2743, 4456, 8332, 1158, 1011, 9156, 478, 1899, 3425, 8485, 2113, 1292, 2558, 747, 6544, 6801, 1084, 8316, 7966, 3376, 6451, 8819, 5549, 294, 4744, 9258, 6610, 6137, 330, 847, 1547, 5241, 7199, 8721, 1961, 7202, 4217, 6930, 5734, 3013, 9657, 3391, 7733, 1498, 9414, 2587, 7158, 4468, 970, 8823, 6964, 1295, 2987, 5460, 9002, 2952, 1006, 7104, 7573, 7524, 3139, 7149, 5314, 3093, 2552, 8614, 1758, 8219, 2731, 1110, 1927, 9474, 3495, 1613, 3043, 5771, 3850, 8022, 5395, 324, 2858, 6595, 2973, 6655, 4647, 652, 2424, 3948, 4615, 9792, 5166, 695, 9909, 387, 9124, 4823, 6589, 8339, 3506, 6262, 6064, 8678, 4011, 3303, 6322, 4741, 2917, 9758, 7586, 2674, 7976, 5829, 5790, 2255, 9388, 2099, 26, 7878, 9983, 2275, 3171, 1172, 3540, 9604, 624, 8623, 159, 1675, 6638, 5737, 8326, 3253, 9964, 8751, 3933, 4519, 5009, 504, 2953, 7719, 6142, 9135, 8610, 1398, 1326, 8322, 5282, 2357, 2096, 10172, 4447, 5087, 9109, 7501, 4564, 8373, 3428, 6463, 6794, 2053, 4200, 237, 2710, 5723, 3878, 4934, 7722, 2070, 3528, 525, 952, 10171, 1730, 6850, 8842, 7352, 8017, 6068, 7213, 9235, 5373, 7434, 3201, 4879, 1171, 1532, 2675, 8967, 6617, 604, 4302, 1595, 6183, 9227, 3824, 4072, 10027, 5437, 5695, 1355, 8773, 9727, 2850, 3166, 9076, 5993, 6880, 7201, 8315, 2928, 7953, 4903, 9916, 9683, 1264, 6233, 3699, 6675, 9411, 3985, 2738, 8590, 5157, 9136, 4014, 7998, 8437, 9145, 9183, 6787, 5819, 1850, 3431, 1632, 4450, 6563, 6860, 9674, 6379, 7891, 4961, 260, 3239, 4284, 1662, 9376, 8214, 191, 1689, 7297, 1769, 7955, 2106, 5203, 5448, 1133, 6866, 111, 5970, 1959, 2536, 9548, 7857, 6862, 9335, 10, 1539, 6387, 3640, 7919, 5702, 1655, 8657, 5627, 2014, 6065, 5659, 6114, 8752, 2720, 6026, 681, 10036, 852, 3714, 2749, 8168, 8755, 7117, 4313, 4856, 2958, 1177, 9516, 1660, 7534, 7078, 3884, 7224, 1302, 1352, 4631, 6793, 1815, 7408, 8143, 6668, 3822, 9664, 5873, 4905, 6827, 957, 7567, 8550, 5480, 2894, 7401, 7806, 258, 6388, 9101, 9009, 6620, 7075, 4421, 8796, 8174, 2933, 6282, 7729, 2348, 7520, 4035, 6619, 4825, 3587, 9656, 7179, 3940, 4584, 5537, 2602, 4183, 9588, 8887, 5089, 2583, 6090, 1857, 5951, 2555, 7532, 153, 413, 6140, 4012, 4819, 1055, 4625, 8897, 5202, 4432, 7790, 3348, 7528, 9047, 1654, 8504, 5562, 843, 4388, 4727, 855, 4942, 6928, 3111, 3569, 3020, 366, 6434, 4869, 679, 6849, 638, 6909, 6798, 617, 4232, 4990, 3740, 4083, 7815, 4560, 5092, 1059, 897, 1348, 8602, 6141, 1887, 6974, 312, 2796, 10076, 9873, 7929, 7956, 6401, 6548, 7685, 7915, 8850, 6330, 5065, 1368, 2736, 3281, 7324, 3080, 28, 7091, 5581, 5633, 8581, 7993, 4739, 5510, 6235, 274, 3996, 2764, 8744, 8632, 4992, 815, 6584, 2721, 6657, 9863, 6534, 1153, 9267, 7222, 798, 5306, 5047, 6175, 7188, 10154, 4707, 506, 9456, 3264, 5611, 5761, 9032, 5080, 6279, 3326, 1494, 2823, 3698, 6352, 6194, 2304, 6367, 9020, 4745, 5578, 2019, 6478, 4489, 8312, 6272, 6084, 6635, 8565, 5766, 4737, 9199, 9108, 8180, 401, 1166, 3542, 1783, 8240, 3713, 2118, 4404, 4452, 2618, 126, 10168, 1698, 1897, 2515, 9030, 1067, 4826, 6196, 10164, 6028, 4673, 8115, 1717, 9737, 3241, 1777, 9253, 6465, 7856, 5151, 7139, 3458, 9113, 429, 7668, 7197, 3599, 8998, 2757, 3753, 5189, 9661, 739, 8455, 2611, 2938, 8048, 8578, 7544, 2067, 9423, 3631, 3662, 841, 6529, 2830, 4875, 1858, 8058, 3630, 3351, 919, 3604, 3299, 5639, 4145, 9547, 6542, 7582, 6859, 5362, 10083, 1554, 4206, 2443, 8247, 3760, 1921, 5540, 7604, 10044, 1012, 615, 1367, 953, 2278, 7009, 9938, 3619, 4694, 8181, 9800, 4316, 4333, 8592, 1351, 1578, 9114, 601, 8038, 4051, 7116, 1640, 2664, 2514, 6308, 4089, 2504, 499, 684, 999, 3035, 5678, 4188, 2718, 2198, 2365, 5733, 2089, 3211, 6857, 9289, 3917, 2612, 1337, 9201, 3065, 5595, 6209, 6616, 7211, 4697, 8914, 926, 1743, 9703, 6976, 7918, 7235, 3375, 3509, 4712, 5904, 9500, 8083, 850, 9822, 5207, 5239, 1641, 966, 9804, 8860, 5257, 2528, 8568, 9859, 8129, 5265, 6371, 2225, 5961, 4824, 3809, 4751, 1518, 7674, 6884, 3580, 2455, 9365, 1793, 4636, 6546, 4701, 8651, 7357, 8513, 103, 5138, 3073, 4649, 4449, 8184, 3379, 10140, 5421, 4196, 6772, 7406, 7350, 340, 5270, 1024, 8770, 5713, 9022, 95, 1686, 4473, 4345, 3102, 323, 5543, 6873, 4228, 3720, 5821, 5427, 4324, 7572, 8303, 7714, 1282, 439, 8811, 8582, 9914, 7758, 3952, 9771, 7327, 10111, 3786, 8050, 7025, 4811, 6195, 4451, 5670, 6835, 9628, 3116, 9954, 2790, 2236, 3922, 1071, 623, 7934, 9747, 5647, 7596, 6157, 5136, 2895, 9279, 3571, 10189, 416, 9600, 4030, 1643, 3218, 1797, 8675, 568, 3859, 6516, 3227, 7413, 4371, 4901, 1807, 9707, 1270, 9659, 5200, 6226, 10058, 5728, 8032, 874, 7889, 6692, 77, 3920, 934, 9690, 2034, 2401, 7514, 7143, 8785, 7792, 2123, 2501, 8696, 9750, 4010, 6215, 3877, 8156, 1394, 2121, 468, 9831, 8798, 7097, 453, 3136, 485, 5909, 4365, 4230, 3071, 6973, 9273, 1029, 3310, 1297, 6327, 3436, 3616, 854, 5181, 4294, 9338, 5964, 229, 6455, 7218, 5722, 1391, 3324, 359, 7477, 6708, 6179, 4470, 4392, 8542, 9791, 5860, 5724, 9361, 3511, 4369, 2088, 9709, 7020, 5186, 5164, 1896, 8756, 7346, 7343, 3328, 7808, 3725, 1191, 7866, 4895, 9056, 2932, 7566, 7074, 5952, 6943, 8505, 4134, 123, 7757, 8440, 8701, 1988, 8275, 6135, 4029, 8492, 5803, 5515, 8114, 5621, 4657, 1102, 10105, 6073, 4810, 4122, 3594, 2942, 1099, 5869, 7100, 9993, 5222, 9643, 5915, 4622, 2211, 7899, 6171, 6642, 2172, 1244, 9084, 8066, 631, 3404, 4979, 6996, 6933, 6725, 1190, 6053, 7054, 9406, 5826, 4212, 6370, 7637, 7239, 1481, 3362, 6467, 2233, 9193, 3715, 7968, 6078, 9620, 3980, 1757, 487, 6228, 5847, 4215, 91, 8754, 8348, 1523, 1181, 8395, 5949, 7047, 8351, 1452, 4600, 2437, 8790, 6703, 6564, 2600, 259, 6689, 4946, 1820, 4956, 1527, 2162, 1429, 9417, 4460, 9670, 2660, 1131, 5963, 6125, 307, 6348, 7483, 1624, 5610, 7061, 10096, 3629, 1733, 4403, 6983, 4868, 5484, 8397, 8558, 619, 6469, 10123, 2060, 5649, 1202, 3840, 1582, 7131, 2213, 1185, 9306, 9008, 6758, 5112, 2896, 3158, 4288, 7585, 9689, 4270, 9408, 4133, 2859, 8108, 7612, 8693, 6212, 9929, 6681, 6705, 6292, 1861, 5567, 1788, 7407, 8383, 8417, 2490, 6054, 7774, 3775, 9900, 918, 2251, 7134, 4775, 4806, 9884, 9666, 7769, 5059, 5561, 6869, 10017, 212, 2910, 1168, 3476, 6353, 6325, 7052, 5379, 8121, 2495, 7960, 8569, 7493, 4774, 4981, 4210, 9899, 8402, 7387, 1572, 5579, 9118, 5238, 602, 8027, 2582, 8082, 4910, 2634, 10122, 7288, 3141, 3119, 4757, 9337, 9347, 10183, 2826, 9760, 3288, 6332, 8331, 5019, 8910, 3647, 2431, 6163, 6193, 4885, 3937, 104, 6344, 4431, 9945, 2485, 4793, 7748, 951, 6980, 6917, 8593, 1854, 7959, 5266, 1585, 981, 2929, 2185, 4059, 9960, 4947, 5542, 6753, 2139, 4566, 10054, 2111, 1370, 3712, 8687, 8246, 1525, 7628, 3524, 3, 7379, 6298, 7060, 2517, 7754, 7910, 2772, 9673, 8172, 927, 2779, 6326, 2367, 7192, 3142, 3229, 3814, 710, 4355, 4255, 6836, 641, 6755, 2921, 4846, 5770, 4859, 273, 2892, 5687, 8875, 6441, 8033, 5864, 9026, 1070, 4952, 6251, 5541, 2176, 6932, 7730, 5522, 3118, 6612, 5660, 8867, 1682, 3801, 3912, 7183, 1560, 5335, 9380, 2700, 3473, 2641, 7310, 9736, 5918, 1558, 5098, 5177, 2791, 1534, 9503, 2330, 6863, 9725, 5033, 6700, 9268, 5546, 1735, 9667, 69, 418, 559, 6497, 4099, 1802, 9980, 2295, 7136, 7882, 3429, 9190, 6752, 8039, 1818, 5751, 4785, 6316, 4367, 8622, 8877, 9572, 9608, 2481, 4520, 7745, 8473, 6706, 904, 9351, 5159, 2418, 6285, 3311, 2930, 8396, 2695, 4076, 7470, 5214, 250, 1570, 1290, 6139, 3200, 176, 4149, 7280, 635, 8808, 8900, 321, 6192, 53, 9806, 6438, 6049, 2122, 959, 3664, 8060, 9234, 4278, 7574, 2306, 110, 3108, 8159, 6143, 7058, 993, 7313, 1960, 2923, 1350, 35, 1165, 8685, 1773, 6896, 10192, 1198, 10026, 4078, 5113, 4465, 2949, 252, 4419, 2182, 1875, 6094, 2314, 293, 4814, 4034, 66, 5349, 7893, 5582, 6907, 6010, 9882, 5622, 161, 4791, 1010, 8142, 1119, 7292, 1461, 4686, 6487, 1021, 751, 598, 3704, 1323, 6201, 7467, 8364, 1163, 9630, 1159, 1789, 9440, 4435, 3972, 9143, 2452, 9868, 7089, 1652, 4275, 3225, 9488, 9367, 9375, 8973, 9064, 7830, 3360, 7172, 6501, 3598, 4782, 5779, 297, 7835, 1331, 7433, 3908, 4533, 1500, 2598, 4927, 3156, 7592, 3322, 4734, 727, 2869, 3990, 10103, 1782, 3129, 4664, 9505, 9264, 3342, 6105, 3084, 1545, 503, 6240, 4140, 8028, 5775, 7369, 8950, 2709, 566, 8252, 474, 9255, 6227, 831, 5675, 6877, 2439, 9685, 5152, 5506, 8652, 4258, 9680, 6625, 45, 6498, 4572, 4556, 8551, 9814, 371, 7616, 965, 574, 4394, 1977, 2813, 2016, 595, 8683, 4809, 4541, 238, 7875, 2983, 4262, 9811, 7159, 177, 3496, 8725, 5684, 5644, 1916, 1795, 1125, 8930, 8600, 5818, 7626, 8825, 764, 4543, 7138, 3398, 8829, 5347, 712, 4763, 6526, 3684, 4156, 8034, 529, 2586, 1801, 5117, 1619, 7657, 4352, 1912, 4409, 7215, 8734, 4827, 9581, 5571, 9851, 7942, 3737, 5135, 8730, 1835, 5937, 3759, 7827, 8270, 393, 5243, 1409, 9603, 3876, 3652, 8100, 4162, 8970, 48, 4877, 2020, 2405, 5736, 10050, 9858, 2272, 4844, 10100, 3966, 9195, 4390, 5831, 6088, 9185, 4950, 8727, 3890, 4021, 4325, 3546, 10091, 9437, 361, 7554, 5405, 1476, 7913, 5184, 1413, 92, 7449, 9729, 9824, 5783, 10162, 1222, 5641, 4789, 2976, 6181, 6306, 10053, 7440, 935, 2323, 454, 3465, 5110, 7650, 9597, 7646, 5563, 3406, 2881, 1407, 1213, 5336, 3287, 8487, 3372, 4641, 987, 8354, 7513, 3893, 3127, 8851, 3380, 3846, 5867, 5298, 2509, 7869, 5056, 4633, 2445, 4724, 2947, 8635, 1608, 130, 5548, 3261, 5269, 7565, 9254, 2615, 3365, 6683, 6161, 2459, 9772, 5380, 1186, 6439, 6208, 3754, 1228, 6686, 3946, 8620, 4839, 2877, 3412, 4163, 537, 7364, 9091, 5865, 528, 7476, 10070, 1546, 3872, 9679, 4931, 2274, 4606, 2156, 9816, 2138, 2690, 2648, 1979, 10195, 3993, 3557, 5905, 2133, 6340, 2963, 5368, 946, 2393, 7029, 3974, 4349, 7679, 7906, 1418, 7900, 9684, 2630, 9894, 6092, 3550, 9852, 6003, 4129, 6086, 4172, 7991, 1756, 2594, 3681, 4264, 5252, 6357, 1306, 6823, 2160, 2465, 2661, 759, 3315, 1388, 4055, 792, 8431, 4565, 1013, 6961, 4553, 5032, 2844, 8491, 3434, 3234, 8015, 2283, 2388, 5142, 8070, 10009, 3179, 8350, 3669, 7128, 9182, 7621, 3958, 2023, 6093, 2891, 8176, 7773, 1026, 9593, 7665, 8072, 5870, 9356, 106, 2633, 7982, 6244, 7040, 4413, 6145, 4528, 2702, 3707, 607, 4893, 4289, 6539, 9849, 6182, 7812, 9978, 573, 4407, 6558, 9116, 2131, 6759, 5655, 5029, 921, 8209, 6355, 6713, 2748, 8045, 211, 6445, 10160, 5872, 3199, 6865, 116, 9274, 7253, 4414, 2887, 4815, 9976, 7615, 1175, 3749, 3442, 72, 7259, 7784, 5832, 9702, 9378, 4860, 7841, 3928, 9621, 2981, 923, 1790, 7430, 326, 3263, 8195, 5844, 8229, 8776, 3392, 9137, 6892, 8895, 1479, 473, 6239, 7677, 1634, 5862, 3220, 2227, 3844, 7698, 5091, 2189, 9562, 2889, 9847, 5286, 9122, 1836, 6637, 8997, 856, 3906, 2197, 7034, 3456, 5559, 8817, 5883, 5512, 7732, 1050, 86, 7992, 3364, 2240, 7846, 3329, 8630, 3531, 4760, 5420, 3029, 6421, 3286, 4439, 9098, 7415, 9434, 7290, 7663, 29, 5215, 2640, 1453, 9021, 2686, 5798, 8489, 1293, 7295, 4764, 2902, 4594, 2032, 5004, 7881, 383, 6712, 8705, 5337, 6779, 1999, 3764, 3451, 1863, 9933, 3121, 7539, 10167, 9904, 9192, 1246, 908, 9961, 3862, 5254, 2177, 2175, 3644, 5143, 4878, 5752, 1096, 389, 7118, 1281, 4224, 8714, 5863, 351, 2129, 9228, 3160, 6180, 6277, 853, 1710, 9225, 3816, 7124, 6671, 5352, 4377, 9710, 288, 5986, 9033, 1645, 1079, 9842, 113, 5174, 3117, 570, 6305, 2912, 2542, 8588, 4493, 6573, 7682, 3612, 6290, 1538, 1676, 1830, 5163, 6939, 3319, 4980, 5635, 7617, 5812, 7095, 8863, 8909, 5658, 1667, 7216, 9653, 7797, 7439, 6951, 5903, 9549, 2380, 9756, 9695, 4362, 431, 8782, 4668, 8475, 8984, 7333, 2208, 4681, 8132, 9663, 8157, 9984, 9115, 8356, 6818, 2596, 1483, 3955, 2652, 4329, 763, 7342, 4132, 102, 5470, 8983, 2371, 2119, 2181, 5604, 8421, 8218, 143, 5377, 1128, 10065, 7114, 7814, 6303, 9046, 5701, 7930, 8580, 7936, 5302, 9812, 3277, 6649, 5564, 4535, 579, 2414, 7914, 7464, 1809, 3973, 9908, 6533, 6767, 7738, 996, 5075, 8814, 5497, 505, 10166, 4384, 6731, 7823, 7490, 1911, 40, 1510, 8783, 10102, 5796, 1062, 5364, 6007, 922, 6568, 2157, 6746, 4983, 2408, 7786, 8982, 8589, 5474, 5900, 3777, 5593, 277, 3077, 9808, 6504, 3910, 2680, 1810, 4561, 8276, 2497, 5889, 5095, 6483, 10144, 9510, 7267, 708, 9042, 7, 8932, 2740, 1853, 1242, 4772, 8091, 3280, 1754, 8769, 236, 8450, 9177, 8119, 8453, 2293, 5868, 9475, 1549, 5399, 5173, 995, 8042, 6842, 7770, 7948, 5367, 5001, 2291, 4441, 9236, 8732, 5198, 3306, 136, 4899, 9888, 1227, 7106, 5859, 6821, 9490, 3732, 1473, 4058, 9580, 2102, 3038, 9723, 4639, 1812, 9748, 1544, 9339, 4176, 1373, 6852, 7794, 6646, 4607, 5328, 4506, 5895, 5534, 4381, 9576, 7002, 4093, 3024, 1170, 5234, 5927, 5201, 7083, 4098, 7332, 7049, 8958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "10196/10196 [==============================] - 8925s 875ms/step - loss: 0.4990 - f1: 0.8165 - acc: 0.8282 - val_loss: 0.6824 - val_f1: 0.7317 - val_acc: 0.7395\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.73170, saving model to unet_resnet_101.hdf5\n",
      "Epoch 2/500\n",
      "10196/10196 [==============================] - 8899s 873ms/step - loss: 0.2542 - f1: 0.9042 - acc: 0.9060 - val_loss: 0.5647 - val_f1: 0.7991 - val_acc: 0.8007\n",
      "\n",
      "Epoch 00002: val_f1 improved from 0.73170 to 0.79906, saving model to unet_resnet_101.hdf5\n",
      "Epoch 3/500\n",
      "10196/10196 [==============================] - 8852s 868ms/step - loss: 0.1521 - f1: 0.9410 - acc: 0.9425 - val_loss: 0.4894 - val_f1: 0.8360 - val_acc: 0.8382\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.79906 to 0.83601, saving model to unet_resnet_101.hdf5\n",
      "Epoch 4/500\n",
      "10196/10196 [==============================] - 8872s 870ms/step - loss: 0.0965 - f1: 0.9605 - acc: 0.9620 - val_loss: 0.5239 - val_f1: 0.8319 - val_acc: 0.8344\n",
      "\n",
      "Epoch 00004: val_f1 did not improve from 0.83601\n",
      "Epoch 5/500\n",
      "10196/10196 [==============================] - 8894s 872ms/step - loss: 0.0689 - f1: 0.9704 - acc: 0.9719 - val_loss: 0.5379 - val_f1: 0.8419 - val_acc: 0.8434\n",
      "\n",
      "Epoch 00005: val_f1 improved from 0.83601 to 0.84185, saving model to unet_resnet_101.hdf5\n",
      "Epoch 6/500\n",
      "10196/10196 [==============================] - 8857s 869ms/step - loss: 0.0527 - f1: 0.9761 - acc: 0.9777 - val_loss: 0.6563 - val_f1: 0.8400 - val_acc: 0.8422\n",
      "\n",
      "Epoch 00006: val_f1 did not improve from 0.84185\n",
      "Epoch 7/500\n",
      "10196/10196 [==============================] - 8857s 869ms/step - loss: 0.0449 - f1: 0.9790 - acc: 0.9804 - val_loss: 0.6232 - val_f1: 0.8486 - val_acc: 0.8499\n",
      "\n",
      "Epoch 00007: val_f1 improved from 0.84185 to 0.84864, saving model to unet_resnet_101.hdf5\n",
      "Epoch 8/500\n",
      "10196/10196 [==============================] - 8880s 871ms/step - loss: 0.0403 - f1: 0.9808 - acc: 0.9820 - val_loss: 0.6861 - val_f1: 0.8433 - val_acc: 0.8455\n",
      "\n",
      "Epoch 00008: val_f1 did not improve from 0.84864\n",
      "Epoch 9/500\n",
      "10196/10196 [==============================] - 8872s 870ms/step - loss: 0.0333 - f1: 0.9833 - acc: 0.9844 - val_loss: 0.7569 - val_f1: 0.8331 - val_acc: 0.8353\n",
      "\n",
      "Epoch 00009: val_f1 did not improve from 0.84864\n",
      "Epoch 10/500\n",
      "10196/10196 [==============================] - 8885s 871ms/step - loss: 0.0329 - f1: 0.9835 - acc: 0.9848 - val_loss: 0.7117 - val_f1: 0.8450 - val_acc: 0.8470\n",
      "\n",
      "Epoch 00010: val_f1 did not improve from 0.84864\n",
      "Epoch 11/500\n",
      "10196/10196 [==============================] - 8849s 868ms/step - loss: 0.0278 - f1: 0.9854 - acc: 0.9867 - val_loss: 0.7906 - val_f1: 0.8450 - val_acc: 0.8471\n",
      "\n",
      "Epoch 00011: val_f1 did not improve from 0.84864\n",
      "Epoch 12/500\n",
      "10196/10196 [==============================] - 8830s 866ms/step - loss: 0.0271 - f1: 0.9857 - acc: 0.9871 - val_loss: 0.7786 - val_f1: 0.8455 - val_acc: 0.8473\n",
      "\n",
      "Epoch 00012: val_f1 did not improve from 0.84864\n",
      "Epoch 13/500\n",
      "10196/10196 [==============================] - 8814s 864ms/step - loss: 0.0230 - f1: 0.9871 - acc: 0.9882 - val_loss: 0.8411 - val_f1: 0.8444 - val_acc: 0.8466\n",
      "\n",
      "Epoch 00013: val_f1 did not improve from 0.84864\n",
      "Epoch 14/500\n",
      "10196/10196 [==============================] - 8829s 866ms/step - loss: 0.0207 - f1: 0.9880 - acc: 0.9892 - val_loss: 0.8618 - val_f1: 0.8484 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00014: val_f1 did not improve from 0.84864\n",
      "Epoch 15/500\n",
      "10196/10196 [==============================] - 8863s 869ms/step - loss: 0.0217 - f1: 0.9877 - acc: 0.9891 - val_loss: 1.0006 - val_f1: 0.8148 - val_acc: 0.8174\n",
      "\n",
      "Epoch 00015: val_f1 did not improve from 0.84864\n",
      "Epoch 16/500\n",
      "10196/10196 [==============================] - 8882s 871ms/step - loss: 0.0226 - f1: 0.9875 - acc: 0.9889 - val_loss: 0.8896 - val_f1: 0.8473 - val_acc: 0.8493\n",
      "\n",
      "Epoch 00016: val_f1 did not improve from 0.84864\n",
      "Epoch 17/500\n",
      "10196/10196 [==============================] - 8876s 871ms/step - loss: 0.0187 - f1: 0.9888 - acc: 0.9903 - val_loss: 0.8822 - val_f1: 0.8468 - val_acc: 0.8488\n",
      "\n",
      "Epoch 00017: val_f1 did not improve from 0.84864\n",
      "Epoch 18/500\n",
      "10196/10196 [==============================] - 8879s 871ms/step - loss: 0.0164 - f1: 0.9897 - acc: 0.9910 - val_loss: 0.9470 - val_f1: 0.8451 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00018: val_f1 did not improve from 0.84864\n",
      "Epoch 19/500\n",
      "10196/10196 [==============================] - 8848s 868ms/step - loss: 0.0157 - f1: 0.9900 - acc: 0.9913 - val_loss: 0.9582 - val_f1: 0.8459 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00019: val_f1 did not improve from 0.84864\n",
      "Epoch 20/500\n",
      "10196/10196 [==============================] - 8844s 867ms/step - loss: 0.0156 - f1: 0.9900 - acc: 0.9914 - val_loss: 0.9951 - val_f1: 0.8443 - val_acc: 0.8467\n",
      "\n",
      "Epoch 00020: val_f1 did not improve from 0.84864\n",
      "Epoch 21/500\n",
      "10196/10196 [==============================] - 8840s 867ms/step - loss: 0.0144 - f1: 0.9905 - acc: 0.9919 - val_loss: 1.0321 - val_f1: 0.8453 - val_acc: 0.8476\n",
      "\n",
      "Epoch 00021: val_f1 did not improve from 0.84864\n",
      "Epoch 22/500\n",
      "10196/10196 [==============================] - 8829s 866ms/step - loss: 0.0146 - f1: 0.9905 - acc: 0.9919 - val_loss: 1.0146 - val_f1: 0.8424 - val_acc: 0.8448\n",
      "\n",
      "Epoch 00022: val_f1 did not improve from 0.84864\n",
      "Epoch 23/500\n",
      "10196/10196 [==============================] - 8823s 865ms/step - loss: 0.0156 - f1: 0.9902 - acc: 0.9917 - val_loss: 1.0136 - val_f1: 0.8456 - val_acc: 0.8482\n",
      "\n",
      "Epoch 00023: val_f1 did not improve from 0.84864\n",
      "Epoch 24/500\n",
      "10196/10196 [==============================] - 8821s 865ms/step - loss: 0.0127 - f1: 0.9912 - acc: 0.9927 - val_loss: 1.0578 - val_f1: 0.8465 - val_acc: 0.8487\n",
      "\n",
      "Epoch 00024: val_f1 did not improve from 0.84864\n",
      "Epoch 25/500\n",
      "10196/10196 [==============================] - 8795s 863ms/step - loss: 0.0121 - f1: 0.9914 - acc: 0.9928 - val_loss: 1.0648 - val_f1: 0.8463 - val_acc: 0.8485\n",
      "\n",
      "Epoch 00025: val_f1 did not improve from 0.84864\n",
      "Epoch 26/500\n",
      "10196/10196 [==============================] - 8764s 860ms/step - loss: 0.0120 - f1: 0.9915 - acc: 0.9929 - val_loss: 0.9012 - val_f1: 0.8361 - val_acc: 0.8391\n",
      "\n",
      "Epoch 00026: val_f1 did not improve from 0.84864\n",
      "Epoch 27/500\n",
      "10196/10196 [==============================] - 8771s 860ms/step - loss: 0.0121 - f1: 0.9915 - acc: 0.9928 - val_loss: 1.0103 - val_f1: 0.8399 - val_acc: 0.8426\n",
      "\n",
      "Epoch 00027: val_f1 did not improve from 0.84864\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Create a Keras Model\n",
    "    model = unet_resnet_101(IMG_WIDTH, IMG_HEIGHT, 3, NB_CLASS)\n",
    "    model.summary()\n",
    "\n",
    "    # 优化器函数\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[f1, 'acc'])\n",
    "\n",
    "    # 获取路径列表\n",
    "    train_crop_top_paths, test_crop_top_paths = get_data_paths(TRAIN_TOP_PATH, VAL_TOP_PATH)\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint('unet_resnet_101.hdf5', monitor='val_f1', mode='max', verbose=1, save_best_only=True)\n",
    "    early_stop = EarlyStopping(monitor='val_f1', mode='max', patience=20)\n",
    "    check_point_list = [model_checkpoint, early_stop]\n",
    "\n",
    "    result = model.fit_generator(\n",
    "        generator=batch_generator(train_crop_top_paths, 1),\n",
    "        steps_per_epoch=10196,\n",
    "        epochs=500,\n",
    "        verbose=1,\n",
    "        validation_data=batch_generator(test_crop_top_paths, 1),\n",
    "        validation_steps=398,\n",
    "        callbacks=check_point_list,\n",
    "        class_weight=[0.7880542, 0.84201391, 1.05645948, 0.94926901, 18.17903545])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\legend.py:641: UserWarning: Unrecognized location \"under right\". Falling back on \"best\"; valid locations are\n",
      "\tbest\n",
      "\tupper right\n",
      "\tupper left\n",
      "\tlower left\n",
      "\tlower right\n",
      "\tright\n",
      "\tcenter left\n",
      "\tcenter right\n",
      "\tlower center\n",
      "\tupper center\n",
      "\tcenter\n",
      "\n",
      "  % (loc, '\\n\\t'.join(self.codes)))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(result.epoch, result.history['f1'], label=\"acc\")\n",
    "plt.plot(result.epoch, result.history['val_f1'], label=\"val_acc\")\n",
    "plt.scatter(result.epoch, result.history['f1'], marker='*')\n",
    "plt.scatter(result.epoch, result.history['val_f1'])\n",
    "plt.legend(loc='under right')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(result.epoch, result.history['loss'], label=\"loss\")\n",
    "plt.plot(result.epoch, result.history['val_loss'], label=\"val_loss\")\n",
    "plt.scatter(result.epoch, result.history['loss'], marker='*')\n",
    "plt.scatter(result.epoch, result.history['val_loss'], marker='*')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "with open('unet_resnet_101.txt', 'w') as f:\n",
    "    f.write(str(result.history))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
